{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary libraries for data loading and EDA\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt, seaborn as sns\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, auc, precision_score, recall_score, roc_auc_score, roc_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the train data\n",
    "df_train = pd.read_csv(r'/home/ducanh/Credit Card Transactions Fraud Detection/Datasets/fraudTrain.csv')\n",
    "df_test = pd.read_csv(r'/home/ducanh/Credit Card Transactions Fraud Detection/Datasets/fraudTest.csv')\n",
    "df = pd.concat([df_train, df_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['trans_date_trans_time'] = pd.to_datetime(df['trans_date_trans_time'])\n",
    "df['trans_hour'] = df['trans_date_trans_time'].dt.time.apply(lambda x: str(x)[:2])\n",
    "\n",
    "df['dob'] = pd.to_datetime(df['dob'])\n",
    "df['cust_age'] = df['dob'].dt.year.apply(lambda x: 2021-x)\n",
    "df['cust_age_groups'] = df['cust_age'].apply(lambda x: 'below 10' if x<10 else ('10-20' if x>=10 and x<20 else ('20-30' if x>=20 and x<30 else('30-40' if x>=30 and x<40 else('40-50' if x>=40 and x<50 else('50-60' if x>=50 and x<60 else('60-70' if x>=60 and x<70 else ('70-80' if x>=70 and x<80 else 'Above 80'))))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_col = ['Unnamed: 0', 'trans_date_trans_time', 'cc_num', 'merchant','first', 'last', 'street', 'city', 'state', 'lat',\n",
    "       'long','dob', 'unix_time', 'cust_age', 'merch_lat',\n",
    "       'merch_long', 'city_pop']\n",
    "df.drop(drop_col, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_piv_2 = pd.pivot_table(data = df,\n",
    "                           index = 'cust_age_groups',\n",
    "                           columns = 'is_fraud',\n",
    "                           values = 'amt',\n",
    "                           aggfunc = np.mean)\n",
    "age_piv_2.sort_values(by = 1, ascending = True, inplace = True)\n",
    "age_dic = {k:v for (k,v) in zip(age_piv_2.index.values, age_piv_2.reset_index().index.values)}\n",
    "df['cust_age_groups'] = df['cust_age_groups'].map(age_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "merch_cat = df[df['is_fraud'] == 1].groupby('category')['amt'].mean().sort_values(ascending = True)\n",
    "merch_cat_dic = {k:v for (k,v) in zip(merch_cat.index.values,merch_cat.reset_index().index.values)}\n",
    "df['category'] = df['category'].map(merch_cat_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_txn_piv_2 = pd.pivot_table(data = df,\n",
    "                               index = 'job',\n",
    "                               columns = 'is_fraud',\n",
    "                               values= 'amt',\n",
    "                               aggfunc = np.mean)\n",
    "job_cat_dic = {k:v for (k,v) in zip(job_txn_piv_2.index.values, job_txn_piv_2.reset_index().index.values)}\n",
    "df['job'] = df['job'].map(job_cat_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['trans_hour'] = df['trans_hour'].astype('int')\n",
    "df = pd.get_dummies(data  = df, columns = ['gender'], drop_first = True, dtype = 'int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1241103, 9)\n",
      "(611291, 9)\n",
      "Shape of training data:  ((1241103, 7), (1241103,))\n",
      "Shape of testing data:  ((611291, 7), (611291,))\n"
     ]
    }
   ],
   "source": [
    "train,test = train_test_split(df, test_size=0.33, random_state=42, stratify = df['is_fraud'])\n",
    "# visualizing class imbalance\n",
    "df['is_fraud'].value_counts()\n",
    "# check\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "\n",
    "# let's drop transaction number columns from both the training and testing data\n",
    "train.drop('trans_num',axis = 1, inplace = True)\n",
    "test.drop('trans_num',axis = 1, inplace = True)\n",
    "# splitting data into dependent and independent features respectively\n",
    "y_train = train['is_fraud']\n",
    "X_train = train.drop('is_fraud',axis = 1)\n",
    "\n",
    "y_test = test['is_fraud']\n",
    "X_test = test.drop('is_fraud',axis = 1)\n",
    "\n",
    "print('Shape of training data: ',(X_train.shape,y_train.shape))\n",
    "print('Shape of testing data: ',(X_test.shape,y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "# scaling the training and testing data\n",
    "X_train_sc = sc.fit_transform(X_train)\n",
    "X_test_sc = sc.transform(X_test)\n",
    "# convert them into dataframes\n",
    "X_train_sc = pd.DataFrame(data = X_train_sc, columns = X_train.columns)\n",
    "X_test_sc = pd.DataFrame(data = X_test_sc, columns = X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = X_train.shape[0]  # Sá»‘ lÆ°á»£ng máº«u trong táº­p train\n",
    "k_initial = int(np.sqrt(N))  \n",
    "if k_initial % 2 == 0:\n",
    "    k_initial += 1  # Äáº£m báº£o k lÃ  sá»‘ láº»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=k_initial)\n",
    "\n",
    "# ðŸ”¥ Huáº¥n luyá»‡n mÃ´ hÃ¬nh trÃªn táº­p train\n",
    "knn.fit(X_train_sc, y_train)\n",
    "\n",
    "# ðŸ“Œ Dá»± Ä‘oÃ¡n xÃ¡c suáº¥t (XÃ¡c suáº¥t thuá»™c lá»›p 1 - fraud)\n",
    "y_pred_train_proba = knn.predict_proba(X_train_sc)\n",
    "y_pred_test_proba = knn.predict_proba(X_test_sc)\n",
    "\n",
    "# LÆ°u káº¿t quáº£ vÃ o DataFrame\n",
    "y_train_results = pd.DataFrame(y_pred_train_proba, columns=['pred_not_fraud', 'pred_fraud'])\n",
    "y_test_results = pd.DataFrame(y_pred_test_proba, columns=['pred_not_fraud', 'pred_fraud'])\n",
    "\n",
    "y_train_results['y_train_actual'] = y_train.values\n",
    "y_test_results['y_test_actual'] = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = [0.1, 0.15, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "for i in numbers:\n",
    "    y_train_results[i] = y_train_results['pred_fraud'].map(lambda x: 1 if x > i else 0)\n",
    "    y_test_results[i] = y_test_results['pred_fraud'].map(lambda x: 1 if x > i else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Œ Train Set Performance:\n",
      "      Threshold  Accuracy  Precision   Recall  F1_score\n",
      "0.10       0.10  0.998754   0.807039  1.00000  0.893217\n",
      "0.15       0.15  0.998754   0.807039  1.00000  0.893217\n",
      "0.20       0.20  0.998754   0.807039  1.00000  0.893217\n",
      "0.30       0.30  0.998754   0.807039  1.00000  0.893217\n",
      "0.40       0.40  0.998754   0.807039  1.00000  0.893217\n",
      "0.50       0.50  0.998306   1.000000  0.67476  0.805799\n",
      "0.60       0.60  0.998306   1.000000  0.67476  0.805799\n",
      "0.70       0.70  0.998306   1.000000  0.67476  0.805799\n",
      "0.80       0.80  0.998306   1.000000  0.67476  0.805799\n",
      "0.90       0.90  0.998306   1.000000  0.67476  0.805799\n",
      "Best Threshold: 0.1000\n",
      "Best Accuracy: 0.9988\n",
      "Best Precision: 0.8070\n",
      "Best Recall: 1.0000\n",
      "Best F1 Score: 0.8932\n",
      "Best ROC_AUC Score: 0.9998\n"
     ]
    }
   ],
   "source": [
    "# ðŸ“Œ TÃ­nh Accuracy, Precision, Recall, F1-score trÃªn táº­p Train\n",
    "cutoff_df = pd.DataFrame(columns=['Threshold', 'Accuracy', 'Precision', 'Recall', 'F1_score'])\n",
    "\n",
    "for i in numbers:\n",
    "    cm1 = confusion_matrix(y_train_results['y_train_actual'], y_train_results[i])\n",
    "    TP, FP, FN, TN = cm1[1, 1], cm1[0, 1], cm1[1, 0], cm1[0, 0]\n",
    "\n",
    "    # TÃ­nh Accuracy, Precision, Recall, F1-score\n",
    "    accuracy = (TP + TN) / (TP + FP + FN + TN)\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    f1_score_value = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    cutoff_df.loc[i] = [i, accuracy, precision, recall, f1_score_value]\n",
    "\n",
    "print(\"ðŸ“Œ Train Set Performance:\")\n",
    "print(cutoff_df)\n",
    "\n",
    "# ðŸ“Œ TÃ¬m Threshold cÃ³ Accuracy cao nháº¥t trÃªn táº­p Train\n",
    "best_idx = cutoff_df['Accuracy'].idxmax()\n",
    "best_threshold = cutoff_df.loc[best_idx, 'Threshold']\n",
    "best_accuracy = cutoff_df.loc[best_idx, 'Accuracy']\n",
    "best_f1_score = cutoff_df.loc[best_idx, 'F1_score']\n",
    "best_precision = cutoff_df.loc[best_idx, 'Precision']\n",
    "best_recall = cutoff_df.loc[best_idx, 'Recall']\n",
    "best_auc = roc_auc_score(y_train_results['y_train_actual'], y_train_results['pred_fraud'])\n",
    "\n",
    "# âœ… In káº¿t quáº£ tá»‘i Æ°u trÃªn Train\n",
    "print(f'Best Threshold: {best_threshold:.4f}')\n",
    "print(f'Best Accuracy: {best_accuracy:.4f}')\n",
    "print(f'Best Precision: {best_precision:.4f}')\n",
    "print(f'Best Recall: {best_recall:.4f}')\n",
    "print(f'Best F1 Score: {best_f1_score:.4f}')\n",
    "print(f'Best ROC_AUC Score: {best_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Œ Test Set Performance:\n",
      "      Threshold  Accuracy  Precision    Recall  F1_score\n",
      "0.10       0.10  0.996316   0.622088  0.746311  0.678561\n",
      "0.15       0.15  0.996316   0.622088  0.746311  0.678561\n",
      "0.20       0.20  0.996316   0.622088  0.746311  0.678561\n",
      "0.30       0.30  0.996316   0.622088  0.746311  0.678561\n",
      "0.40       0.40  0.996316   0.622088  0.746311  0.678561\n",
      "0.50       0.50  0.997422   0.900050  0.568289  0.696690\n",
      "0.60       0.60  0.997422   0.900050  0.568289  0.696690\n",
      "0.70       0.70  0.997422   0.900050  0.568289  0.696690\n",
      "0.80       0.80  0.997422   0.900050  0.568289  0.696690\n",
      "0.90       0.90  0.997422   0.900050  0.568289  0.696690\n",
      "Best Threshold: 0.5000\n",
      "Best Accuracy: 0.9974\n",
      "Best Precision: 0.9000\n",
      "Best Recall: 0.5683\n",
      "Best F1 Score: 0.6967\n",
      "Best ROC_AUC Score: 0.8725\n"
     ]
    }
   ],
   "source": [
    "# ðŸ“Œ TÃ­nh Accuracy, Precision, Recall, F1-score trÃªn táº­p Test\n",
    "cutoff_df = pd.DataFrame(columns=['Threshold', 'Accuracy', 'Precision', 'Recall', 'F1_score'])\n",
    "\n",
    "for i in numbers:\n",
    "    cm1 = confusion_matrix(y_test_results['y_test_actual'], y_test_results[i])\n",
    "    TP, FP, FN, TN = cm1[1, 1], cm1[0, 1], cm1[1, 0], cm1[0, 0]\n",
    "\n",
    "    # TÃ­nh Accuracy, Precision, Recall, F1-score\n",
    "    accuracy = (TP + TN) / (TP + FP + FN + TN)\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    f1_score_value = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    cutoff_df.loc[i] = [i, accuracy, precision, recall, f1_score_value]\n",
    "\n",
    "print(\"ðŸ“Œ Test Set Performance:\")\n",
    "print(cutoff_df)\n",
    "\n",
    "# ðŸ“Œ TÃ¬m Threshold cÃ³ Accuracy cao nháº¥t trÃªn táº­p Test\n",
    "best_idx = cutoff_df['Accuracy'].idxmax()\n",
    "best_threshold = cutoff_df.loc[best_idx, 'Threshold']\n",
    "best_accuracy = cutoff_df.loc[best_idx, 'Accuracy']\n",
    "best_f1_score = cutoff_df.loc[best_idx, 'F1_score']\n",
    "best_precision = cutoff_df.loc[best_idx, 'Precision']\n",
    "best_recall = cutoff_df.loc[best_idx, 'Recall']\n",
    "best_auc = roc_auc_score(y_test_results['y_test_actual'], y_test_results['pred_fraud'])\n",
    "\n",
    "# âœ… In káº¿t quáº£ tá»‘i Æ°u trÃªn Test\n",
    "print(f'Best Threshold: {best_threshold:.4f}')\n",
    "print(f'Best Accuracy: {best_accuracy:.4f}')\n",
    "print(f'Best Precision: {best_precision:.4f}')\n",
    "print(f'Best Recall: {best_recall:.4f}')\n",
    "print(f'Best F1 Score: {best_f1_score:.4f}')\n",
    "print(f'Best ROC_AUC Score: {best_auc:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
