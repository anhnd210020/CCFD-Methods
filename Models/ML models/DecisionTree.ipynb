{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary libraries for data loading and EDA\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt, seaborn as sns\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, auc, precision_score, recall_score, roc_auc_score, roc_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the train data\n",
    "df_train = pd.read_csv(r'/home/ducanh/Credit Card Transactions Fraud Detection/Datasets/fraudTrain.csv')\n",
    "df_test = pd.read_csv(r'/home/ducanh/Credit Card Transactions Fraud Detection/Datasets/fraudTest.csv')\n",
    "df = pd.concat([df_train, df_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['trans_date_trans_time'] = pd.to_datetime(df['trans_date_trans_time'])\n",
    "df['trans_hour'] = df['trans_date_trans_time'].dt.time.apply(lambda x: str(x)[:2])\n",
    "\n",
    "df['dob'] = pd.to_datetime(df['dob'])\n",
    "df['cust_age'] = df['dob'].dt.year.apply(lambda x: 2021-x)\n",
    "df['cust_age_groups'] = df['cust_age'].apply(lambda x: 'below 10' if x<10 else ('10-20' if x>=10 and x<20 else ('20-30' if x>=20 and x<30 else('30-40' if x>=30 and x<40 else('40-50' if x>=40 and x<50 else('50-60' if x>=50 and x<60 else('60-70' if x>=60 and x<70 else ('70-80' if x>=70 and x<80 else 'Above 80'))))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_col = ['Unnamed: 0', 'trans_date_trans_time', 'cc_num', 'merchant','first', 'last', 'street', 'city', 'state', 'lat',\n",
    "       'long','dob', 'unix_time', 'cust_age', 'merch_lat',\n",
    "       'merch_long', 'city_pop']\n",
    "df.drop(drop_col, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_piv_2 = pd.pivot_table(data = df,\n",
    "                           index = 'cust_age_groups',\n",
    "                           columns = 'is_fraud',\n",
    "                           values = 'amt',\n",
    "                           aggfunc = np.mean)\n",
    "age_piv_2.sort_values(by = 1, ascending = True, inplace = True)\n",
    "age_dic = {k:v for (k,v) in zip(age_piv_2.index.values, age_piv_2.reset_index().index.values)}\n",
    "df['cust_age_groups'] = df['cust_age_groups'].map(age_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "merch_cat = df[df['is_fraud'] == 1].groupby('category')['amt'].mean().sort_values(ascending = True)\n",
    "merch_cat_dic = {k:v for (k,v) in zip(merch_cat.index.values,merch_cat.reset_index().index.values)}\n",
    "df['category'] = df['category'].map(merch_cat_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_txn_piv_2 = pd.pivot_table(data = df,\n",
    "                               index = 'job',\n",
    "                               columns = 'is_fraud',\n",
    "                               values= 'amt',\n",
    "                               aggfunc = np.mean)\n",
    "job_cat_dic = {k:v for (k,v) in zip(job_txn_piv_2.index.values, job_txn_piv_2.reset_index().index.values)}\n",
    "df['job'] = df['job'].map(job_cat_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['trans_hour'] = df['trans_hour'].astype('int')\n",
    "df = pd.get_dummies(data  = df, columns = ['gender'], drop_first = True, dtype = 'int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1241103, 9)\n",
      "(611291, 9)\n",
      "Shape of training data:  ((1241103, 7), (1241103,))\n",
      "Shape of testing data:  ((611291, 7), (611291,))\n"
     ]
    }
   ],
   "source": [
    "train,test = train_test_split(df, test_size=0.33, random_state=42, stratify = df['is_fraud'])\n",
    "# visualizing class imbalance\n",
    "df['is_fraud'].value_counts()\n",
    "# check\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "\n",
    "# let's drop transaction number columns from both the training and testing data\n",
    "train.drop('trans_num',axis = 1, inplace = True)\n",
    "test.drop('trans_num',axis = 1, inplace = True)\n",
    "# splitting data into dependent and independent features respectively\n",
    "y_train = train['is_fraud']\n",
    "X_train = train.drop('is_fraud',axis = 1)\n",
    "\n",
    "y_test = test['is_fraud']\n",
    "X_test = test.drop('is_fraud',axis = 1)\n",
    "\n",
    "print('Shape of training data: ',(X_train.shape,y_train.shape))\n",
    "print('Shape of testing data: ',(X_test.shape,y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "# scaling the training and testing data\n",
    "X_train_sc = sc.fit_transform(X_train)\n",
    "X_test_sc = sc.transform(X_test)\n",
    "# convert them into dataframes\n",
    "X_train_sc = pd.DataFrame(data = X_train_sc, columns = X_train.columns)\n",
    "X_test_sc = pd.DataFrame(data = X_test_sc, columns = X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model = DecisionTreeClassifier(class_weight='balanced', random_state=42)\n",
    "dt_model.fit(X_train_sc, y_train)\n",
    "\n",
    "y_pred_train_proba = dt_model.predict_proba(X_train_sc)\n",
    "y_pred_test_proba = dt_model.predict_proba(X_test_sc)\n",
    "\n",
    "y_train_results = pd.DataFrame(y_pred_train_proba, columns=['pred_not_fraud', 'pred_fraud'])\n",
    "y_test_results = pd.DataFrame(y_pred_test_proba, columns=['pred_not_fraud', 'pred_fraud'])\n",
    "\n",
    "y_train_results['y_train_actual'] = y_train.values\n",
    "y_test_results['y_test_actual'] = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create columns with different probability cutoffs\n",
    "numbers = [0.1, 0.15, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "for i in numbers:\n",
    "    y_train_results[i] = y_train_results.pred_fraud.map(lambda x: 1 if x > i else 0)\n",
    "    y_test_results[i] = y_test_results.pred_fraud.map(lambda x: 1 if x > i else 0)\n",
    "\n",
    "cutoff_df = pd.DataFrame(columns=['Threshold', 'precision_score', 'recall_score', 'F1_score', 'Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Threshold  precision_score  recall_score  F1_score  Accuracy\n",
      "0.10       0.10         0.999845           1.0  0.999923  0.999999\n",
      "0.15       0.15         0.999845           1.0  0.999923  0.999999\n",
      "0.20       0.20         0.999845           1.0  0.999923  0.999999\n",
      "0.30       0.30         0.999845           1.0  0.999923  0.999999\n",
      "0.40       0.40         0.999845           1.0  0.999923  0.999999\n",
      "0.50       0.50         0.999845           1.0  0.999923  0.999999\n",
      "0.60       0.60         0.999845           1.0  0.999923  0.999999\n",
      "0.70       0.70         0.999845           1.0  0.999923  0.999999\n",
      "0.80       0.80         0.999845           1.0  0.999923  0.999999\n",
      "0.90       0.90         0.999845           1.0  0.999923  0.999999\n",
      "Best Threshold: 0.1000\n",
      "Best Accuracy: 1.0000\n",
      "Best Precision: 0.9998\n",
      "Best Recall: 1.0000\n",
      "Best F1 Score: 0.9999\n",
      "Best ROC_AUC Score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "for i in numbers:\n",
    "    cm1 = confusion_matrix(y_train_results['y_train_actual'], y_train_results[i])\n",
    "    TP, FP, FN, TN = cm1[1,1], cm1[0,1], cm1[1,0], cm1[0,0]\n",
    "    \n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    f1_score_value = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    \n",
    "    cutoff_df.loc[i] = [i, precision, recall, f1_score_value, accuracy]\n",
    "\n",
    "print(cutoff_df)\n",
    "\n",
    "best_idx = cutoff_df['F1_score'].idxmax()\n",
    "best_threshold = cutoff_df.loc[best_idx, 'Threshold']\n",
    "best_f1_score = cutoff_df.loc[best_idx, 'F1_score']\n",
    "best_precision = cutoff_df.loc[best_idx, 'precision_score']\n",
    "best_recall = cutoff_df.loc[best_idx, 'recall_score']\n",
    "best_accuracy = cutoff_df.loc[best_idx, 'Accuracy']\n",
    "best_auc = roc_auc_score(y_train_results['y_train_actual'], y_train_results[best_threshold])\n",
    "\n",
    "print(f'Best Threshold: {best_threshold:.4f}')\n",
    "print(f'Best Accuracy: {best_accuracy:.4f}')\n",
    "print(f'Best Precision: {best_precision:.4f}')\n",
    "print(f'Best Recall: {best_recall:.4f}')\n",
    "print(f'Best F1 Score: {best_f1_score:.4f}')\n",
    "print(f'Best ROC_AUC Score: {best_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Threshold  precision_score  recall_score  F1_score  Accuracy\n",
      "0.10       0.10         0.808923      0.785557  0.797069  0.997916\n",
      "0.15       0.15         0.808923      0.785557  0.797069  0.997916\n",
      "0.20       0.20         0.808923      0.785557  0.797069  0.997916\n",
      "0.30       0.30         0.808923      0.785557  0.797069  0.997916\n",
      "0.40       0.40         0.808923      0.785557  0.797069  0.997916\n",
      "0.50       0.50         0.808923      0.785557  0.797069  0.997916\n",
      "0.60       0.60         0.808923      0.785557  0.797069  0.997916\n",
      "0.70       0.70         0.808923      0.785557  0.797069  0.997916\n",
      "0.80       0.80         0.808923      0.785557  0.797069  0.997916\n",
      "0.90       0.90         0.808923      0.785557  0.797069  0.997916\n",
      "Best Threshold: 0.1000\n",
      "Best Accuracy: 0.9979\n",
      "Best Precision: 0.8089\n",
      "Best Recall: 0.7856\n",
      "Best F1 Score: 0.7971\n",
      "Best ROC_AUC Score: 0.8923\n"
     ]
    }
   ],
   "source": [
    "for i in numbers:\n",
    "    cm1 = confusion_matrix(y_test_results['y_test_actual'], y_test_results[i])\n",
    "    TP, FP, FN, TN = cm1[1,1], cm1[0,1], cm1[1,0], cm1[0,0]\n",
    "    \n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    f1_score_value = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    \n",
    "    cutoff_df.loc[i] = [i, precision, recall, f1_score_value, accuracy]\n",
    "\n",
    "print(cutoff_df)\n",
    "\n",
    "best_idx = cutoff_df['F1_score'].idxmax()\n",
    "best_threshold = cutoff_df.loc[best_idx, 'Threshold']\n",
    "best_f1_score = cutoff_df.loc[best_idx, 'F1_score']\n",
    "best_precision = cutoff_df.loc[best_idx, 'precision_score']\n",
    "best_recall = cutoff_df.loc[best_idx, 'recall_score']\n",
    "best_accuracy = cutoff_df.loc[best_idx, 'Accuracy']\n",
    "best_auc = roc_auc_score(y_test_results['y_test_actual'], y_test_results[best_threshold])\n",
    "\n",
    "print(f'Best Threshold: {best_threshold:.4f}')\n",
    "print(f'Best Accuracy: {best_accuracy:.4f}')\n",
    "print(f'Best Precision: {best_precision:.4f}')\n",
    "print(f'Best Recall: {best_recall:.4f}')\n",
    "print(f'Best F1 Score: {best_f1_score:.4f}')\n",
    "print(f'Best ROC_AUC Score: {best_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuDNN version (built with TensorFlow): 9\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "build_info = tf.sysconfig.get_build_info()\n",
    "print(\"cuDNN version (built with TensorFlow):\", build_info.get(\"cudnn_version\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
