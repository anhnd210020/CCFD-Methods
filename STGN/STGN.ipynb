{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tổng số sequence: 1296675\n",
      "--------------------------------------------------\n",
      "Sequence 1: shape torch.Size([5, 4])\n",
      "--------------------------------------------------\n",
      "Sequence 2: shape torch.Size([5, 4])\n",
      "--------------------------------------------------\n",
      "Sequence 3: shape torch.Size([5, 4])\n",
      "--------------------------------------------------\n",
      "Sequence 4: shape torch.Size([5, 4])\n",
      "--------------------------------------------------\n",
      "Sequence 5: shape torch.Size([5, 4])\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from geopy.distance import geodesic  # Compute distance between transactions\n",
    "\n",
    "# Dataset class with only 4 features: category, amt, distance_km, delta_t\n",
    "class CreditCardFraudDataset(Dataset):\n",
    "    def __init__(self, file_path, seq_len):\n",
    "        self.data = pd.read_csv(file_path)\n",
    "\n",
    "        # Convert transaction date to timestamp\n",
    "        self.data['trans_date_trans_time'] = pd.to_datetime(self.data['trans_date_trans_time']).apply(lambda x: x.timestamp())\n",
    "\n",
    "        # Encode category column\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.data['category'] = self.label_encoder.fit_transform(self.data['category'])\n",
    "\n",
    "        # Normalize numerical features\n",
    "        scaler = MinMaxScaler()\n",
    "        self.data[['amt']] = scaler.fit_transform(self.data[['amt']])\n",
    "\n",
    "        # Compute distance between transactions\n",
    "        self.data['prev_lat'] = self.data.groupby('cc_num')['lat'].shift(1)\n",
    "        self.data['prev_long'] = self.data.groupby('cc_num')['long'].shift(1)\n",
    "        self.data['distance_km'] = self.data.apply(\n",
    "            lambda row: geodesic((row['lat'], row['long']), (row['prev_lat'], row['prev_long'])).km\n",
    "            if not pd.isnull(row['prev_lat']) else 0, axis=1\n",
    "        )\n",
    "\n",
    "        # Normalize distance\n",
    "        self.data[['distance_km']] = scaler.fit_transform(self.data[['distance_km']])\n",
    "\n",
    "        # Group transactions by `cc_num` and create sequences\n",
    "        self.seq_len = seq_len\n",
    "        self.sequences = []\n",
    "        grouped = self.data.groupby('cc_num')\n",
    "\n",
    "        for _, group in grouped:\n",
    "            # Selecting only 4 features: category, amt, distance_km, time_intervals (delta_t)\n",
    "            # Lưu ý: dữ liệu ban đầu có 5 cột: category, amt, distance_km, is_fraud, trans_date_trans_time\n",
    "            group = group[['category', 'amt', 'distance_km', 'is_fraud', 'trans_date_trans_time']].values\n",
    "\n",
    "            for i in range(len(group)):\n",
    "                if i < self.seq_len - 1:\n",
    "                    padding = [group[0]] * (self.seq_len - i - 1)\n",
    "                    seq = padding + group[:i + 1].tolist()\n",
    "                else:\n",
    "                    seq = group[i - self.seq_len + 1:i + 1].tolist()\n",
    "\n",
    "                label = group[i, -2]  # Fraud label\n",
    "                time_intervals = np.diff([s[-1] for s in seq], prepend=seq[0][-1])  # Time differences\n",
    "                time_intervals = time_intervals.reshape(-1, 1)\n",
    "\n",
    "                # Final sequence with only 4 features: category, amt, distance_km, delta_t\n",
    "                # Lưu ý: dùng s[:-1] loại bỏ cột timestamp (trans_date_trans_time)\n",
    "                # => Các cột còn lại là: category, amt, distance_km, is_fraud\n",
    "                # Chúng ta cần loại bỏ is_fraud vì nó dùng làm nhãn, do đó thay đổi thành s[:-2]\n",
    "                seq_features = np.array([s[:-2] for s in seq])  # Remove is_fraud and timestamp\n",
    "                seq_features = np.concatenate((seq_features, time_intervals), axis=1)  # Add time intervals\n",
    "\n",
    "                self.sequences.append((seq_features, label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x_seq, y_label = self.sequences[idx]\n",
    "        return torch.tensor(x_seq, dtype=torch.float32), torch.tensor(y_label, dtype=torch.float32)\n",
    "\n",
    "# --- Bổ sung bước cuối để kiểm tra shape của seq_features ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Thay 'your_file.csv' bằng đường dẫn file CSV thật của bạn.\n",
    "    file_path = \"/home/ducanh/Credit Card Transactions Fraud Detection/Datasets/fraudTrain.csv\"\n",
    "    seq_len = 5  # Ví dụ: chuỗi gồm 5 giao dịch\n",
    "    dataset = CreditCardFraudDataset(file_path, seq_len)\n",
    "    \n",
    "    print(\"Tổng số sequence:\", len(dataset))\n",
    "    print(\"-\" * 50)\n",
    "    # Kiểm tra shape của 5 sequence đầu tiên\n",
    "    for i in range(min(5, len(dataset))):\n",
    "        x_seq, y_label = dataset[i]\n",
    "        print(f\"Sequence {i+1}: shape {x_seq.shape}\")\n",
    "        # Nếu bạn muốn xem chi tiết các giá trị, hãy bỏ comment dòng dưới đây:\n",
    "        # print(x_seq)\n",
    "        print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tổng số sequence: 1296675\n",
      "--------------------------------------------------\n",
      "Shape của sequence đầu tiên (x_seq): torch.Size([5, 4])\n",
      "--------------------------------------------------\n",
      "Shape của x_seq có batch dimension: torch.Size([1, 5, 4])\n",
      "--------------------------------------------------\n",
      "At timestep 0, x_t shape: torch.Size([1, 2])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x2 and 4x64)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 149\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m    148\u001b[0m \u001b[38;5;66;03m# Forward pass qua model (sẽ in ra shape của x_t tại mỗi timestep)\u001b[39;00m\n\u001b[0;32m--> 149\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_seq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput của model:\u001b[39m\u001b[38;5;124m\"\u001b[39m, output)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[2], line 115\u001b[0m, in \u001b[0;36mSTGN_LSTM.forward\u001b[0;34m(self, X_seq)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt timestep \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, x_t shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx_t\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;66;03m# Tính các cổng (gates)\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m f_t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mWfh(h_prev) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWfx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_t\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbf)\n\u001b[1;32m    116\u001b[0m i_t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mWih(h_prev) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mWix(x_t) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbi)\n\u001b[1;32m    117\u001b[0m T_t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mWTh(h_prev) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mWTx(x_t) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mWTt(delta_t) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbT)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x2 and 4x64)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from geopy.distance import geodesic  # Compute distance between transactions\n",
    "\n",
    "# Dataset class with only 4 features: category, amt, distance_km, delta_t\n",
    "class CreditCardFraudDataset(Dataset):\n",
    "    def __init__(self, file_path, seq_len):\n",
    "        self.data = pd.read_csv(file_path)\n",
    "\n",
    "        # Convert transaction date to timestamp\n",
    "        self.data['trans_date_trans_time'] = pd.to_datetime(self.data['trans_date_trans_time']).apply(lambda x: x.timestamp())\n",
    "\n",
    "        # Encode category column\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.data['category'] = self.label_encoder.fit_transform(self.data['category'])\n",
    "\n",
    "        # Normalize numerical features\n",
    "        scaler = MinMaxScaler()\n",
    "        self.data[['amt']] = scaler.fit_transform(self.data[['amt']])\n",
    "\n",
    "        # Compute distance between transactions\n",
    "        self.data['prev_lat'] = self.data.groupby('cc_num')['lat'].shift(1)\n",
    "        self.data['prev_long'] = self.data.groupby('cc_num')['long'].shift(1)\n",
    "        self.data['distance_km'] = self.data.apply(\n",
    "            lambda row: geodesic((row['lat'], row['long']), (row['prev_lat'], row['prev_long'])).km\n",
    "            if not pd.isnull(row['prev_lat']) else 0, axis=1\n",
    "        )\n",
    "\n",
    "        # Normalize distance\n",
    "        self.data[['distance_km']] = scaler.fit_transform(self.data[['distance_km']])\n",
    "\n",
    "        # Group transactions by `cc_num` and create sequences\n",
    "        self.seq_len = seq_len\n",
    "        self.sequences = []\n",
    "        grouped = self.data.groupby('cc_num')\n",
    "\n",
    "        for _, group in grouped:\n",
    "            # Selecting only 4 features: category, amt, distance_km, time_intervals (delta_t)\n",
    "            # Dữ liệu ban đầu có 5 cột: [category, amt, distance_km, is_fraud, trans_date_trans_time]\n",
    "            group = group[['category', 'amt', 'distance_km', 'is_fraud', 'trans_date_trans_time']].values\n",
    "\n",
    "            for i in range(len(group)):\n",
    "                if i < self.seq_len - 1:\n",
    "                    padding = [group[0]] * (self.seq_len - i - 1)\n",
    "                    seq = padding + group[:i + 1].tolist()\n",
    "                else:\n",
    "                    seq = group[i - self.seq_len + 1:i + 1].tolist()\n",
    "\n",
    "                label = group[i, -2]  # Fraud label (is_fraud)\n",
    "                time_intervals = np.diff([s[-1] for s in seq], prepend=seq[0][-1])  # Compute delta_t\n",
    "                time_intervals = time_intervals.reshape(-1, 1)\n",
    "\n",
    "                # Final sequence with only 4 features: category, amt, distance_km, delta_t\n",
    "                # Loại bỏ 2 cột cuối: is_fraud và trans_date_trans_time\n",
    "                seq_features = np.array([s[:-2] for s in seq])\n",
    "                # Nối thêm delta_t (time_intervals)\n",
    "                seq_features = np.concatenate((seq_features, time_intervals), axis=1)\n",
    "\n",
    "                self.sequences.append((seq_features, label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x_seq, y_label = self.sequences[idx]\n",
    "        return torch.tensor(x_seq, dtype=torch.float32), torch.tensor(y_label, dtype=torch.float32)\n",
    "\n",
    "# LSTM Model with Time & Location-aware modules\n",
    "class STGN_LSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(STGN_LSTM, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # LSTM Gates with Time & Location-aware module\n",
    "        self.Wfh = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.Wfx = nn.Linear(input_dim, hidden_dim)\n",
    "        self.bf = nn.Parameter(torch.zeros(hidden_dim))\n",
    "\n",
    "        self.Wih = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.Wix = nn.Linear(input_dim, hidden_dim)\n",
    "        self.bi = nn.Parameter(torch.zeros(hidden_dim))\n",
    "\n",
    "        self.WTh = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.WTx = nn.Linear(input_dim, hidden_dim)\n",
    "        self.WTt = nn.Linear(1, hidden_dim)\n",
    "        self.bT = nn.Parameter(torch.zeros(hidden_dim))\n",
    "\n",
    "        self.WLh = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.WLx = nn.Linear(input_dim, hidden_dim)\n",
    "        self.WLdelta = nn.Linear(1, hidden_dim)\n",
    "        self.bL = nn.Parameter(torch.zeros(hidden_dim))\n",
    "\n",
    "        self.classifier = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, X_seq):\n",
    "        batch_size, seq_len, _ = X_seq.shape\n",
    "        h_prev = torch.zeros(batch_size, self.hidden_dim).to(X_seq.device)\n",
    "        c_prev = torch.zeros(batch_size, self.hidden_dim).to(X_seq.device)\n",
    "\n",
    "        for t in range(seq_len):\n",
    "            # Lấy x_t từ các cột đầu tiên, loại bỏ 2 cột cuối (delta_t và delta_L)\n",
    "            x_t = X_seq[:, t, :-2]\n",
    "            # Tách riêng delta_t và delta_L từ 2 cột cuối\n",
    "            delta_t = X_seq[:, t, -2].view(-1, 1)\n",
    "            delta_L = X_seq[:, t, -1].view(-1, 1)\n",
    "            \n",
    "            # In ra shape của x_t tại mỗi bước thời gian\n",
    "            print(f\"At timestep {t}, x_t shape: {x_t.shape}\")\n",
    "\n",
    "            # Tính các cổng (gates)\n",
    "            f_t = torch.sigmoid(self.Wfh(h_prev) + self.Wfx(x_t) + self.bf)\n",
    "            i_t = torch.sigmoid(self.Wih(h_prev) + self.Wix(x_t) + self.bi)\n",
    "            T_t = torch.sigmoid(self.WTh(h_prev) + self.WTx(x_t) + self.WTt(delta_t) + self.bT)\n",
    "            L_t = torch.sigmoid(self.WLh(h_prev) + self.WLx(x_t) + self.WLdelta(delta_L) + self.bL)\n",
    "\n",
    "            c_t = f_t * c_prev + i_t * torch.tanh(T_t * delta_t + L_t * delta_L)\n",
    "            h_t = torch.tanh(c_t)\n",
    "            h_prev, c_prev = h_t, c_t  # Cập nhật trạng thái cho bước tiếp theo\n",
    "\n",
    "        return torch.sigmoid(self.classifier(h_t))\n",
    "\n",
    "# --- Main ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Thay 'your_file.csv' bằng đường dẫn file CSV thật của bạn\n",
    "    file_path = \"/home/ducanh/Credit Card Transactions Fraud Detection/Datasets/fraudTrain.csv\"\n",
    "    seq_len = 5  # Ví dụ: mỗi sequence gồm 5 giao dịch\n",
    "    dataset = CreditCardFraudDataset(file_path, seq_len)\n",
    "    print(\"Tổng số sequence:\", len(dataset))\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Kiểm tra shape của sequence đầu tiên\n",
    "    x_seq, y_label = dataset[0]\n",
    "    print(\"Shape của sequence đầu tiên (x_seq):\", x_seq.shape)\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Khởi tạo model với input_dim = 4 (category, amt, distance_km, delta_t) và hidden_dim = 64\n",
    "    model = STGN_LSTM(input_dim=4, hidden_dim=64)\n",
    "    \n",
    "    # Thêm batch dimension (giả sử batch size = 1)\n",
    "    x_seq = x_seq.unsqueeze(0)  # Shape: (1, seq_len, 4)\n",
    "    print(\"Shape của x_seq có batch dimension:\", x_seq.shape)\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Forward pass qua model (sẽ in ra shape của x_t tại mỗi timestep)\n",
    "    output = model(x_seq)\n",
    "    print(\"Output của model:\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from geopy.distance import geodesic  # Compute distance between transactions\n",
    "\n",
    "# Dataset class with only 4 features: category, amt, distance_km, delta_t\n",
    "class CreditCardFraudDataset(Dataset):\n",
    "    def __init__(self, file_path, seq_len):\n",
    "        self.data = pd.read_csv(file_path)\n",
    "\n",
    "        # Convert transaction date to timestamp\n",
    "        self.data['trans_date_trans_time'] = pd.to_datetime(self.data['trans_date_trans_time']).apply(lambda x: x.timestamp())\n",
    "\n",
    "        # Encode category column\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.data['category'] = self.label_encoder.fit_transform(self.data['category'])\n",
    "\n",
    "        # Normalize numerical features\n",
    "        scaler = MinMaxScaler()\n",
    "        self.data[['amt']] = scaler.fit_transform(self.data[['amt']])\n",
    "\n",
    "        # Compute distance between transactions\n",
    "        self.data['prev_lat'] = self.data.groupby('cc_num')['lat'].shift(1)\n",
    "        self.data['prev_long'] = self.data.groupby('cc_num')['long'].shift(1)\n",
    "        self.data['distance_km'] = self.data.apply(\n",
    "            lambda row: geodesic((row['lat'], row['long']), (row['prev_lat'], row['prev_long'])).km\n",
    "            if not pd.isnull(row['prev_lat']) else 0, axis=1\n",
    "        )\n",
    "\n",
    "        # Normalize distance\n",
    "        self.data[['distance_km']] = scaler.fit_transform(self.data[['distance_km']])\n",
    "\n",
    "        # Group transactions by `cc_num` and create sequences\n",
    "        self.seq_len = seq_len\n",
    "        self.sequences = []\n",
    "        grouped = self.data.groupby('cc_num')\n",
    "\n",
    "        for _, group in grouped:\n",
    "            # Selecting only 4 features: category, amt, distance_km, time_intervals (delta_t)\n",
    "            group = group[['category', 'amt', 'distance_km', 'is_fraud', 'trans_date_trans_time']].values\n",
    "\n",
    "            for i in range(len(group)):\n",
    "                if i < self.seq_len - 1:\n",
    "                    padding = [group[0]] * (self.seq_len - i - 1)\n",
    "                    seq = padding + group[:i + 1].tolist()\n",
    "                else:\n",
    "                    seq = group[i - self.seq_len + 1:i + 1].tolist()\n",
    "\n",
    "                label = group[i, -2]  # Fraud label\n",
    "                time_intervals = np.diff([s[-1] for s in seq], prepend=seq[0][-1])  # Time differences\n",
    "                time_intervals = time_intervals.reshape(-1, 1)\n",
    "\n",
    "                # Final sequence with only 4 features: category, amt, distance_km, delta_t\n",
    "                seq_features = np.array([s[:-1] for s in seq])  # Remove timestamp\n",
    "                seq_features = np.concatenate((seq_features, time_intervals), axis=1)  # Add time intervals\n",
    "\n",
    "                self.sequences.append((seq_features, label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x_seq, y_label = self.sequences[idx]\n",
    "        return torch.tensor(x_seq, dtype=torch.float32), torch.tensor(y_label, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from geopy.distance import geodesic  # Compute distance between transactions\n",
    "\n",
    "# Dataset class with only 4 features: category, amt, distance_km, delta_t\n",
    "class CreditCardFraudDataset(Dataset):\n",
    "    def __init__(self, file_path, seq_len):\n",
    "        self.data = pd.read_csv(file_path)\n",
    "\n",
    "        # Convert transaction date to timestamp\n",
    "        self.data['trans_date_trans_time'] = pd.to_datetime(self.data['trans_date_trans_time']).apply(lambda x: x.timestamp())\n",
    "\n",
    "        # Encode category column\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.data['category'] = self.label_encoder.fit_transform(self.data['category'])\n",
    "\n",
    "        # Normalize numerical features\n",
    "        scaler = MinMaxScaler()\n",
    "        self.data[['amt']] = scaler.fit_transform(self.data[['amt']])\n",
    "\n",
    "        # Compute distance between transactions\n",
    "        self.data['prev_lat'] = self.data.groupby('cc_num')['lat'].shift(1)\n",
    "        self.data['prev_long'] = self.data.groupby('cc_num')['long'].shift(1)\n",
    "        self.data['distance_km'] = self.data.apply(\n",
    "            lambda row: geodesic((row['lat'], row['long']), (row['prev_lat'], row['prev_long'])).km\n",
    "            if not pd.isnull(row['prev_lat']) else 0, axis=1\n",
    "        )\n",
    "\n",
    "        # Normalize distance\n",
    "        self.data[['distance_km']] = scaler.fit_transform(self.data[['distance_km']])\n",
    "\n",
    "        # Group transactions by `cc_num` and create sequences\n",
    "        self.seq_len = seq_len\n",
    "        self.sequences = []\n",
    "        grouped = self.data.groupby('cc_num')\n",
    "\n",
    "        for _, group in grouped:\n",
    "            # Selecting only 4 features: category, amt, distance_km, time_intervals (delta_t)\n",
    "            group = group[['category', 'amt', 'distance_km', 'is_fraud', 'trans_date_trans_time']].values\n",
    "\n",
    "            for i in range(len(group)):\n",
    "                if i < self.seq_len - 1:\n",
    "                    padding = [group[0]] * (self.seq_len - i - 1)\n",
    "                    seq = padding + group[:i + 1].tolist()\n",
    "                else:\n",
    "                    seq = group[i - self.seq_len + 1:i + 1].tolist()\n",
    "\n",
    "                label = group[i, -2]  # Fraud label\n",
    "                time_intervals = np.diff([s[-1] for s in seq], prepend=seq[0][-1])  # Time differences\n",
    "                time_intervals = time_intervals.reshape(-1, 1)\n",
    "\n",
    "                # Final sequence with only 4 features: category, amt, distance_km, delta_t\n",
    "                seq_features = np.array([s[:-1] for s in seq])  # Remove timestamp\n",
    "                seq_features = np.concatenate((seq_features, time_intervals), axis=1)  # Add time intervals\n",
    "\n",
    "                self.sequences.append((seq_features, label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x_seq, y_label = self.sequences[idx]\n",
    "        return torch.tensor(x_seq, dtype=torch.float32), torch.tensor(y_label, dtype=torch.float32)\n",
    "\n",
    "\n",
    "# LSTM Model for Fraud Detection with 4 features\n",
    "class STGN_LSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(STGN_LSTM, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # LSTM Gates with Time & Location-aware module\n",
    "        self.Wfh = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.Wfx = nn.Linear(input_dim, hidden_dim)\n",
    "        self.bf = nn.Parameter(torch.zeros(hidden_dim))\n",
    "\n",
    "        self.Wih = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.Wix = nn.Linear(input_dim, hidden_dim)\n",
    "        self.bi = nn.Parameter(torch.zeros(hidden_dim))\n",
    "\n",
    "        self.WTh = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.WTx = nn.Linear(input_dim, hidden_dim)\n",
    "        self.WTt = nn.Linear(1, hidden_dim)\n",
    "        self.bT = nn.Parameter(torch.zeros(hidden_dim))\n",
    "\n",
    "        self.WLh = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.WLx = nn.Linear(input_dim, hidden_dim)\n",
    "        self.WLdelta = nn.Linear(1, hidden_dim)\n",
    "        self.bL = nn.Parameter(torch.zeros(hidden_dim))\n",
    "\n",
    "        self.classifier = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, X_seq):\n",
    "        batch_size, seq_len, _ = X_seq.shape\n",
    "        h_prev = torch.zeros(batch_size, self.hidden_dim).to(X_seq.device)\n",
    "        c_prev = torch.zeros(batch_size, self.hidden_dim).to(X_seq.device)\n",
    "\n",
    "        for t in range(seq_len):\n",
    "            x_t = X_seq[:, t, :-2]  # Features excluding delta_t, delta L\n",
    "            delta_t = X_seq[:, t, -2].view(-1, 1)  # Time interval (delta_t)  \n",
    "            delta_L = X_seq[:, t, -1].view(-1, 1)  # Distance interval (delta_L)\n",
    "            # Gates\n",
    "            f_t = torch.sigmoid(self.Wfh(h_prev) + self.Wfx(x_t) + self.bf)\n",
    "            i_t = torch.sigmoid(self.Wih(h_prev) + self.Wix(x_t) + self.bi)\n",
    "            T_t = torch.sigmoid(self.WTh(h_prev) + self.WTx(x_t) + self.WTt(delta_t) + self.bT)\n",
    "            L_t = torch.sigmoid(self.WLh(h_prev) + self.WLx(x_t) + self.WLdelta(delta_L) + self.bL)\n",
    "\n",
    "            c_t = f_t * c_prev + i_t * torch.tanh(T_t * delta_t + L_t * delta_L)\n",
    "            h_t = torch.tanh(c_t)\n",
    "\n",
    "        return torch.sigmoid(self.classifier(h_t))\n",
    "\n",
    "batch_size = 32\n",
    "input_dim = 4 # Now using only 4 features: category, amt, distance_km, delta_t\n",
    "hidden_dim = 64\n",
    "seq_len = 5\n",
    "\n",
    "train_dataset = CreditCardFraudDataset(\"/home/ducanh/Credit Card Transactions Fraud Detection/Datasets/fraudTrain.csv\", seq_len)\n",
    "test_dataset = CreditCardFraudDataset(\"/home/ducanh/Credit Card Transactions Fraud Detection/Datasets/fraudTest.csv\", seq_len)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
