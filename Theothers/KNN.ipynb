{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary libraries for data loading and EDA\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt, seaborn as sns\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, auc, precision_score, recall_score, roc_auc_score, roc_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the train data\n",
    "df_train = pd.read_csv(r'/home/ducanh/Credit Card Transactions Fraud Detection/Datasets/fraudTrain.csv')\n",
    "df_test = pd.read_csv(r'/home/ducanh/Credit Card Transactions Fraud Detection/Datasets/fraudTest.csv')\n",
    "df = pd.concat([df_train, df_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['trans_date_trans_time'] = pd.to_datetime(df['trans_date_trans_time'])\n",
    "df['trans_hour'] = df['trans_date_trans_time'].dt.time.apply(lambda x: str(x)[:2])\n",
    "\n",
    "df['dob'] = pd.to_datetime(df['dob'])\n",
    "df['cust_age'] = df['dob'].dt.year.apply(lambda x: 2021-x)\n",
    "df['cust_age_groups'] = df['cust_age'].apply(lambda x: 'below 10' if x<10 else ('10-20' if x>=10 and x<20 else ('20-30' if x>=20 and x<30 else('30-40' if x>=30 and x<40 else('40-50' if x>=40 and x<50 else('50-60' if x>=50 and x<60 else('60-70' if x>=60 and x<70 else ('70-80' if x>=70 and x<80 else 'Above 80'))))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_col = ['Unnamed: 0', 'trans_date_trans_time', 'cc_num', 'merchant','first', 'last', 'street', 'city', 'state', 'lat',\n",
    "       'long','dob', 'unix_time', 'cust_age', 'merch_lat',\n",
    "       'merch_long', 'city_pop']\n",
    "df.drop(drop_col, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_piv_2 = pd.pivot_table(data = df,\n",
    "                           index = 'cust_age_groups',\n",
    "                           columns = 'is_fraud',\n",
    "                           values = 'amt',\n",
    "                           aggfunc = np.mean)\n",
    "age_piv_2.sort_values(by = 1, ascending = True, inplace = True)\n",
    "age_dic = {k:v for (k,v) in zip(age_piv_2.index.values, age_piv_2.reset_index().index.values)}\n",
    "df['cust_age_groups'] = df['cust_age_groups'].map(age_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "merch_cat = df[df['is_fraud'] == 1].groupby('category')['amt'].mean().sort_values(ascending = True)\n",
    "merch_cat_dic = {k:v for (k,v) in zip(merch_cat.index.values,merch_cat.reset_index().index.values)}\n",
    "df['category'] = df['category'].map(merch_cat_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_txn_piv_2 = pd.pivot_table(data = df,\n",
    "                               index = 'job',\n",
    "                               columns = 'is_fraud',\n",
    "                               values= 'amt',\n",
    "                               aggfunc = np.mean)\n",
    "job_cat_dic = {k:v for (k,v) in zip(job_txn_piv_2.index.values, job_txn_piv_2.reset_index().index.values)}\n",
    "df['job'] = df['job'].map(job_cat_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['trans_hour'] = df['trans_hour'].astype('int')\n",
    "df = pd.get_dummies(data  = df, columns = ['gender'], drop_first = True, dtype = 'int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1241103, 9)\n",
      "(611291, 9)\n",
      "Shape of training data:  ((1241103, 7), (1241103,))\n",
      "Shape of testing data:  ((611291, 7), (611291,))\n"
     ]
    }
   ],
   "source": [
    "train,test = train_test_split(df, test_size=0.33, random_state=42, stratify = df['is_fraud'])\n",
    "# visualizing class imbalance\n",
    "df['is_fraud'].value_counts()\n",
    "# check\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "\n",
    "# let's drop transaction number columns from both the training and testing data\n",
    "train.drop('trans_num',axis = 1, inplace = True)\n",
    "test.drop('trans_num',axis = 1, inplace = True)\n",
    "# splitting data into dependent and independent features respectively\n",
    "y_train = train['is_fraud']\n",
    "X_train = train.drop('is_fraud',axis = 1)\n",
    "\n",
    "y_test = test['is_fraud']\n",
    "X_test = test.drop('is_fraud',axis = 1)\n",
    "\n",
    "print('Shape of training data: ',(X_train.shape,y_train.shape))\n",
    "print('Shape of testing data: ',(X_test.shape,y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "# scaling the training and testing data\n",
    "X_train_sc = sc.fit_transform(X_train)\n",
    "X_test_sc = sc.transform(X_test)\n",
    "# convert them into dataframes\n",
    "X_train_sc = pd.DataFrame(data = X_train_sc, columns = X_train.columns)\n",
    "X_test_sc = pd.DataFrame(data = X_test_sc, columns = X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = X_train.shape[0]  # Số lượng mẫu trong tập train\n",
    "k_initial = int(np.sqrt(N))  \n",
    "if k_initial % 2 == 0:\n",
    "    k_initial += 1  # Đảm bảo k là số lẻ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=k_initial)\n",
    "\n",
    "# 🔥 Huấn luyện mô hình trên tập train\n",
    "knn.fit(X_train_sc, y_train)\n",
    "\n",
    "# 📌 Dự đoán xác suất (Xác suất thuộc lớp 1 - fraud)\n",
    "y_pred_train_proba = knn.predict_proba(X_train_sc)\n",
    "y_pred_test_proba = knn.predict_proba(X_test_sc)\n",
    "\n",
    "# Lưu kết quả vào DataFrame\n",
    "y_train_results = pd.DataFrame(y_pred_train_proba, columns=['pred_not_fraud', 'pred_fraud'])\n",
    "y_test_results = pd.DataFrame(y_pred_test_proba, columns=['pred_not_fraud', 'pred_fraud'])\n",
    "\n",
    "y_train_results['y_train_actual'] = y_train.values\n",
    "y_test_results['y_test_actual'] = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = [0.1, 0.15, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "for i in numbers:\n",
    "    y_train_results[i] = y_train_results['pred_fraud'].map(lambda x: 1 if x > i else 0)\n",
    "    y_test_results[i] = y_test_results['pred_fraud'].map(lambda x: 1 if x > i else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 Train Set Performance:\n",
      "      Threshold  Accuracy  Precision   Recall  F1_score\n",
      "0.10       0.10  0.998754   0.807039  1.00000  0.893217\n",
      "0.15       0.15  0.998754   0.807039  1.00000  0.893217\n",
      "0.20       0.20  0.998754   0.807039  1.00000  0.893217\n",
      "0.30       0.30  0.998754   0.807039  1.00000  0.893217\n",
      "0.40       0.40  0.998754   0.807039  1.00000  0.893217\n",
      "0.50       0.50  0.998306   1.000000  0.67476  0.805799\n",
      "0.60       0.60  0.998306   1.000000  0.67476  0.805799\n",
      "0.70       0.70  0.998306   1.000000  0.67476  0.805799\n",
      "0.80       0.80  0.998306   1.000000  0.67476  0.805799\n",
      "0.90       0.90  0.998306   1.000000  0.67476  0.805799\n",
      "Best Threshold: 0.1000\n",
      "Best Accuracy: 0.9988\n",
      "Best Precision: 0.8070\n",
      "Best Recall: 1.0000\n",
      "Best F1 Score: 0.8932\n",
      "Best ROC_AUC Score: 0.9998\n"
     ]
    }
   ],
   "source": [
    "# 📌 Tính Accuracy, Precision, Recall, F1-score trên tập Train\n",
    "cutoff_df = pd.DataFrame(columns=['Threshold', 'Accuracy', 'Precision', 'Recall', 'F1_score'])\n",
    "\n",
    "for i in numbers:\n",
    "    cm1 = confusion_matrix(y_train_results['y_train_actual'], y_train_results[i])\n",
    "    TP, FP, FN, TN = cm1[1, 1], cm1[0, 1], cm1[1, 0], cm1[0, 0]\n",
    "\n",
    "    # Tính Accuracy, Precision, Recall, F1-score\n",
    "    accuracy = (TP + TN) / (TP + FP + FN + TN)\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    f1_score_value = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    cutoff_df.loc[i] = [i, accuracy, precision, recall, f1_score_value]\n",
    "\n",
    "print(\"📌 Train Set Performance:\")\n",
    "print(cutoff_df)\n",
    "\n",
    "# 📌 Tìm Threshold có Accuracy cao nhất trên tập Train\n",
    "best_idx = cutoff_df['Accuracy'].idxmax()\n",
    "best_threshold = cutoff_df.loc[best_idx, 'Threshold']\n",
    "best_accuracy = cutoff_df.loc[best_idx, 'Accuracy']\n",
    "best_f1_score = cutoff_df.loc[best_idx, 'F1_score']\n",
    "best_precision = cutoff_df.loc[best_idx, 'Precision']\n",
    "best_recall = cutoff_df.loc[best_idx, 'Recall']\n",
    "best_auc = roc_auc_score(y_train_results['y_train_actual'], y_train_results['pred_fraud'])\n",
    "\n",
    "# ✅ In kết quả tối ưu trên Train\n",
    "print(f'Best Threshold: {best_threshold:.4f}')\n",
    "print(f'Best Accuracy: {best_accuracy:.4f}')\n",
    "print(f'Best Precision: {best_precision:.4f}')\n",
    "print(f'Best Recall: {best_recall:.4f}')\n",
    "print(f'Best F1 Score: {best_f1_score:.4f}')\n",
    "print(f'Best ROC_AUC Score: {best_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 Test Set Performance:\n",
      "      Threshold  Accuracy  Precision    Recall  F1_score\n",
      "0.10       0.10  0.996316   0.622088  0.746311  0.678561\n",
      "0.15       0.15  0.996316   0.622088  0.746311  0.678561\n",
      "0.20       0.20  0.996316   0.622088  0.746311  0.678561\n",
      "0.30       0.30  0.996316   0.622088  0.746311  0.678561\n",
      "0.40       0.40  0.996316   0.622088  0.746311  0.678561\n",
      "0.50       0.50  0.997422   0.900050  0.568289  0.696690\n",
      "0.60       0.60  0.997422   0.900050  0.568289  0.696690\n",
      "0.70       0.70  0.997422   0.900050  0.568289  0.696690\n",
      "0.80       0.80  0.997422   0.900050  0.568289  0.696690\n",
      "0.90       0.90  0.997422   0.900050  0.568289  0.696690\n",
      "Best Threshold: 0.5000\n",
      "Best Accuracy: 0.9974\n",
      "Best Precision: 0.9000\n",
      "Best Recall: 0.5683\n",
      "Best F1 Score: 0.6967\n",
      "Best ROC_AUC Score: 0.8725\n"
     ]
    }
   ],
   "source": [
    "# 📌 Tính Accuracy, Precision, Recall, F1-score trên tập Test\n",
    "cutoff_df = pd.DataFrame(columns=['Threshold', 'Accuracy', 'Precision', 'Recall', 'F1_score'])\n",
    "\n",
    "for i in numbers:\n",
    "    cm1 = confusion_matrix(y_test_results['y_test_actual'], y_test_results[i])\n",
    "    TP, FP, FN, TN = cm1[1, 1], cm1[0, 1], cm1[1, 0], cm1[0, 0]\n",
    "\n",
    "    # Tính Accuracy, Precision, Recall, F1-score\n",
    "    accuracy = (TP + TN) / (TP + FP + FN + TN)\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    f1_score_value = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    cutoff_df.loc[i] = [i, accuracy, precision, recall, f1_score_value]\n",
    "\n",
    "print(\"📌 Test Set Performance:\")\n",
    "print(cutoff_df)\n",
    "\n",
    "# 📌 Tìm Threshold có Accuracy cao nhất trên tập Test\n",
    "best_idx = cutoff_df['Accuracy'].idxmax()\n",
    "best_threshold = cutoff_df.loc[best_idx, 'Threshold']\n",
    "best_accuracy = cutoff_df.loc[best_idx, 'Accuracy']\n",
    "best_f1_score = cutoff_df.loc[best_idx, 'F1_score']\n",
    "best_precision = cutoff_df.loc[best_idx, 'Precision']\n",
    "best_recall = cutoff_df.loc[best_idx, 'Recall']\n",
    "best_auc = roc_auc_score(y_test_results['y_test_actual'], y_test_results['pred_fraud'])\n",
    "\n",
    "# ✅ In kết quả tối ưu trên Test\n",
    "print(f'Best Threshold: {best_threshold:.4f}')\n",
    "print(f'Best Accuracy: {best_accuracy:.4f}')\n",
    "print(f'Best Precision: {best_precision:.4f}')\n",
    "print(f'Best Recall: {best_recall:.4f}')\n",
    "print(f'Best F1 Score: {best_f1_score:.4f}')\n",
    "print(f'Best ROC_AUC Score: {best_auc:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
