# %% Import các thư viện cần thiết
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, accuracy_score, confusion_matrix
from sklearn.model_selection import train_test_split  # nếu cần dùng sau này
import warnings
warnings.filterwarnings('ignore')
# %% Đọc dữ liệu riêng biệt cho Train và Test
df_train = pd.read_csv(r'/home/ducanh/Credit Card Transactions Fraud Detection/Datasets/combined_fraudTrain.csv')
df_test = pd.read_csv(r'/home/ducanh/Credit Card Transactions Fraud Detection/Datasets/combined_fraudTest.csv')


# %% Tách features và nhãn cho từng tập
y_train = df_train['is_fraud']
X_train = df_train.drop('is_fraud', axis=1)

y_test = df_test['is_fraud']
X_test = df_test.drop('is_fraud', axis=1)

print("Shape of training data:", (X_train.shape, y_train.shape))
print("Shape of testing data:", (X_test.shape, y_test.shape))

# %% Scaling dữ liệu
sc = StandardScaler()
X_train_sc = sc.fit_transform(X_train)
X_test_sc = sc.transform(X_test)

# Convert lại thành DataFrame để giữ tên cột
X_train_sc = pd.DataFrame(data=X_train_sc, columns=X_train.columns)
X_test_sc = pd.DataFrame(data=X_test_sc, columns=X_test.columns)

# %% Tạo sequence
sequence_length = 1  # Ở đây bạn dùng 1 giao dịch làm 1 sequence

def create_sequences_predict_all(df, sequence_length):
    sequences, labels = [], []
    # Nhóm theo cc_num
    grouped = df.groupby('cc_num')
    for user_id, group in grouped:
        # Sắp xếp theo trans_date_trans_time
        group = group.sort_values(by='trans_date_trans_time')
        # Lấy các giá trị (loại bỏ 'is_fraud' và 'cc_num')
        values = group.drop(columns=['is_fraud', 'cc_num']).values
        targets = group['is_fraud'].values
        n = len(group)
        for i in range(n):
            if i < sequence_length:
                pad_needed = sequence_length - (i + 1)
                pad = np.repeat(values[0:1, :], pad_needed, axis=0)
                seq = np.concatenate((pad, values[:i+1]), axis=0)
            else:
                seq = values[i-sequence_length+1:i+1]
            sequences.append(seq)
            labels.append(targets[i])
    return np.array(sequences), np.array(labels)

# Gộp thêm cột 'is_fraud' vào DataFrame chuẩn hóa để tạo sequence
train_seq_df = X_train_sc.copy()
train_seq_df['is_fraud'] = y_train.values

test_seq_df = X_test_sc.copy()
test_seq_df['is_fraud'] = y_test.values

X_train_seq, y_train_seq = create_sequences_predict_all(train_seq_df, sequence_length)
X_test_seq, y_test_seq = create_sequences_predict_all(test_seq_df, sequence_length)

print("Sequence shape (train):", X_train_seq.shape)
print("Sequence shape (test):", X_test_seq.shape)

# %% Tạo Dataset và DataLoader cho GRU
class FraudDataset(Dataset):
    def __init__(self, X, y):
        self.X = X  # shape: (num_sequences, sequence_length, num_features)
        self.y = y

    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        return self.X[idx], self.y[idx]

batch_size = 64
train_dataset = FraudDataset(torch.tensor(X_train_seq, dtype=torch.float32),
                               torch.tensor(y_train_seq, dtype=torch.float32))
test_dataset = FraudDataset(torch.tensor(X_test_seq, dtype=torch.float32),
                              torch.tensor(y_test_seq, dtype=torch.float32))

train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

# %% Xây dựng mô hình GRU
class FraudGRU(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers):
        super(FraudGRU, self).__init__()
        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_size, 1)
        self.sigmoid = nn.Sigmoid()
    
    def forward(self, x):
        out, _ = self.gru(x)
        out = self.fc(out[:, -1, :])  # Lấy trạng thái ẩn của bước cuối
        return self.sigmoid(out)

# %% Hàm huấn luyện mô hình
def train_model(model, train_loader, criterion, optimizer, num_epochs, device):
    best_loss = float('inf')
    for epoch in range(num_epochs):
        model.train()
        total_loss = 0
        for X_batch, y_batch in train_loader:
            X_batch, y_batch = X_batch.to(device), y_batch.to(device)
            optimizer.zero_grad()
            outputs = model(X_batch).squeeze()
            loss = criterion(outputs, y_batch)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        
        average_loss = total_loss / len(train_loader)
        print(f'Epoch {epoch + 1}, Loss: {average_loss:.4f}')
        # Lưu checkpoint
        torch.save(model.state_dict(), 'last.pth')
        if average_loss < best_loss:
            best_loss = average_loss
            torch.save(model.state_dict(), 'best.pth')

# %% Cấu hình và huấn luyện mô hình
input_size = X_train_seq.shape[2]  # số feature sau khi loại bỏ cc_num
hidden_size = 64
num_layers = 2
model = FraudGRU(input_size, hidden_size, num_layers)

criterion = nn.BCELoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

num_epochs = 20
train_model(model, train_loader, criterion, optimizer, num_epochs, device)

# %% Dự đoán và đánh giá mô hình
model.eval()
y_pred_train_proba = []
with torch.no_grad():
    for X_batch, y_batch in train_loader:
        X_batch = X_batch.to(device)
        outputs = model(X_batch).squeeze().cpu().numpy()
        y_pred_train_proba.extend(outputs)
y_pred_train_proba = np.array(y_pred_train_proba)

y_pred_test_proba = []
with torch.no_grad():
    for X_batch, y_batch in test_loader:
        X_batch = X_batch.to(device)
        outputs = model(X_batch).squeeze().cpu().numpy()
        y_pred_test_proba.extend(outputs)
y_pred_test_proba = np.array(y_pred_test_proba)

# Tạo DataFrame kết quả
y_train_results = pd.DataFrame(y_pred_train_proba, columns=['pred_fraud'])
y_train_results['pred_not_fraud'] = 1 - y_train_results['pred_fraud']
y_train_results['y_train_actual'] = y_train_seq

y_test_results = pd.DataFrame(y_pred_test_proba, columns=['pred_fraud'])
y_test_results['pred_not_fraud'] = 1 - y_test_results['pred_fraud']
y_test_results['y_test_actual'] = y_test_seq

# Đánh giá theo các ngưỡng khác nhau
numbers = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]
cutoff_df_train = pd.DataFrame(columns=['Threshold', 'Accuracy', 'precision_score', 'recall_score', 'F1_score'])
for thresh in numbers:
    preds = y_train_results['pred_fraud'].map(lambda x: 1 if x > thresh else 0)
    cm = confusion_matrix(y_train_results['y_train_actual'], preds)
    TP, FP, FN, TN = cm[1,1], cm[0,1], cm[1,0], cm[0,0]
    precision_val = TP / (TP + FP) if (TP + FP) > 0 else 0
    recall_val = TP / (TP + FN) if (TP + FN) > 0 else 0
    f1_val = (2 * precision_val * recall_val) / (precision_val + recall_val) if (precision_val + recall_val) > 0 else 0
    accuracy_val = (TP + TN) / (TP + TN + FP + FN)
    cutoff_df_train.loc[thresh] = [thresh, accuracy_val, precision_val, recall_val, f1_val]

print("Train Evaluation:")
print(cutoff_df_train)

cutoff_df_test = pd.DataFrame(columns=['Threshold', 'Accuracy', 'precision_score', 'recall_score', 'F1_score'])
for thresh in numbers:
    preds = y_test_results['pred_fraud'].map(lambda x: 1 if x > thresh else 0)
    cm = confusion_matrix(y_test_results['y_test_actual'], preds)
    TP, FP, FN, TN = cm[1,1], cm[0,1], cm[1,0], cm[0,0]
    precision_val = TP / (TP + FP) if (TP + FP) > 0 else 0
    recall_val = TP / (TP + FN) if (TP + FN) > 0 else 0
    f1_val = (2 * precision_val * recall_val) / (precision_val + recall_val) if (precision_val + recall_val) > 0 else 0
    accuracy_val = (TP + TN) / (TP + TN + FP + FN)
    cutoff_df_test.loc[thresh] = [thresh, accuracy_val, precision_val, recall_val, f1_val]

print("Test Evaluation:")
print(cutoff_df_test)

best_idx_train = cutoff_df_train['F1_score'].idxmax()
best_thresh_train = cutoff_df_train.loc[best_idx_train, 'Threshold']
best_auc_train = roc_auc_score(y_train_results['y_train_actual'], y_train_results['pred_fraud'])
print(f'\nTrain Best Threshold: {best_thresh_train:.4f}')
print(f'Train Best ROC_AUC Score: {best_auc_train:.4f}')

best_idx_test = cutoff_df_test['F1_score'].idxmax()
best_thresh_test = cutoff_df_test.loc[best_idx_test, 'Threshold']
best_auc_test = roc_auc_score(y_test_results['y_test_actual'], y_test_results['pred_fraud'])
print(f'\nTest Best Threshold: {best_thresh_test:.4f}')
print(f'Test Best ROC_AUC Score: {best_auc_test:.4f}')