{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing necessary libraries for data loading and EDA\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt, seaborn as sns\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, auc, precision_score, recall_score, roc_auc_score, roc_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the train data\n",
    "df_train = pd.read_csv(r'/home/ducanh/Credit Card Transactions Fraud Detection/Datasets/fraudTrain.csv')\n",
    "df_test = pd.read_csv(r'/home/ducanh/Credit Card Transactions Fraud Detection/Datasets/fraudTest.csv')\n",
    "df = pd.concat([df_train, df_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['trans_date_trans_time'] = pd.to_datetime(df['trans_date_trans_time'])\n",
    "df['trans_hour'] = df['trans_date_trans_time'].dt.time.apply(lambda x: str(x)[:2])\n",
    "\n",
    "df['dob'] = pd.to_datetime(df['dob'])\n",
    "df['cust_age'] = df['dob'].dt.year.apply(lambda x: 2021-x)\n",
    "df['cust_age_groups'] = df['cust_age'].apply(lambda x: 'below 10' if x<10 else ('10-20' if x>=10 and x<20 else ('20-30' if x>=20 and x<30 else('30-40' if x>=30 and x<40 else('40-50' if x>=40 and x<50 else('50-60' if x>=50 and x<60 else('60-70' if x>=60 and x<70 else ('70-80' if x>=70 and x<80 else 'Above 80'))))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_col = ['Unnamed: 0', 'trans_date_trans_time', 'cc_num', 'merchant','first', 'last', 'street', 'city', 'state', 'lat',\n",
    "       'long','dob', 'unix_time', 'cust_age', 'merch_lat',\n",
    "       'merch_long', 'city_pop']\n",
    "df.drop(drop_col, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_piv_2 = pd.pivot_table(data = df,\n",
    "                           index = 'cust_age_groups',\n",
    "                           columns = 'is_fraud',\n",
    "                           values = 'amt',\n",
    "                           aggfunc = np.mean)\n",
    "age_piv_2.sort_values(by = 1, ascending = True, inplace = True)\n",
    "age_dic = {k:v for (k,v) in zip(age_piv_2.index.values, age_piv_2.reset_index().index.values)}\n",
    "df['cust_age_groups'] = df['cust_age_groups'].map(age_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "merch_cat = df[df['is_fraud'] == 1].groupby('category')['amt'].mean().sort_values(ascending = True)\n",
    "merch_cat_dic = {k:v for (k,v) in zip(merch_cat.index.values,merch_cat.reset_index().index.values)}\n",
    "df['category'] = df['category'].map(merch_cat_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_txn_piv_2 = pd.pivot_table(data = df,\n",
    "                               index = 'job',\n",
    "                               columns = 'is_fraud',\n",
    "                               values= 'amt',\n",
    "                               aggfunc = np.mean)\n",
    "job_cat_dic = {k:v for (k,v) in zip(job_txn_piv_2.index.values, job_txn_piv_2.reset_index().index.values)}\n",
    "df['job'] = df['job'].map(job_cat_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['trans_hour'] = df['trans_hour'].astype('int')\n",
    "df = pd.get_dummies(data  = df, columns = ['gender'], drop_first = True, dtype = 'int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1241103, 9)\n",
      "(611291, 9)\n",
      "Shape of training data:  ((1241103, 7), (1241103,))\n",
      "Shape of testing data:  ((611291, 7), (611291,))\n"
     ]
    }
   ],
   "source": [
    "train,test = train_test_split(df, test_size=0.33, random_state=42, stratify = df['is_fraud'])\n",
    "# visualizing class imbalance\n",
    "df['is_fraud'].value_counts()\n",
    "# check\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "\n",
    "# let's drop transaction number columns from both the training and testing data\n",
    "train.drop('trans_num',axis = 1, inplace = True)\n",
    "test.drop('trans_num',axis = 1, inplace = True)\n",
    "# splitting data into dependent and independent features respectively\n",
    "y_train = train['is_fraud']\n",
    "X_train = train.drop('is_fraud',axis = 1)\n",
    "\n",
    "y_test = test['is_fraud']\n",
    "X_test = test.drop('is_fraud',axis = 1)\n",
    "\n",
    "print('Shape of training data: ',(X_train.shape,y_train.shape))\n",
    "print('Shape of testing data: ',(X_test.shape,y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "# scaling the training and testing data\n",
    "X_train_sc = sc.fit_transform(X_train)\n",
    "X_test_sc = sc.transform(X_test)\n",
    "# convert them into dataframes\n",
    "X_train_sc = pd.DataFrame(data = X_train_sc, columns = X_train.columns)\n",
    "X_test_sc = pd.DataFrame(data = X_test_sc, columns = X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', scale_pos_weight=(y_train.value_counts()[0] / y_train.value_counts()[1]), random_state=42, n_estimators=100)\n",
    "xgb_model.fit(X_train_sc, y_train)\n",
    "\n",
    "y_pred_train_proba = xgb_model.predict_proba(X_train_sc)\n",
    "y_pred_test_proba = xgb_model.predict_proba(X_test_sc)\n",
    "\n",
    "y_train_results = pd.DataFrame(y_pred_train_proba, columns=['pred_not_fraud', 'pred_fraud'])\n",
    "y_test_results = pd.DataFrame(y_pred_test_proba, columns=['pred_not_fraud', 'pred_fraud'])\n",
    "\n",
    "y_train_results['y_train_actual'] = y_train.values\n",
    "y_test_results['y_test_actual'] = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = [0.1, 0.15, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "for i in numbers:\n",
    "    y_train_results[i] = y_train_results.pred_fraud.map(lambda x: 1 if x > i else 0)\n",
    "    y_test_results[i] = y_test_results.pred_fraud.map(lambda x: 1 if x > i else 0)\n",
    "\n",
    "cutoff_df = pd.DataFrame(columns=['Threshold', 'precision_score', 'recall_score', 'F1_score', 'Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Threshold  precision_score  recall_score  F1_score  Accuracy\n",
      "0.10       0.10         0.157792      1.000000  0.272574  0.972192\n",
      "0.15       0.15         0.189252      1.000000  0.318271  0.977681\n",
      "0.20       0.20         0.218151      1.000000  0.358168  0.981328\n",
      "0.30       0.30         0.268901      1.000000  0.423833  0.985835\n",
      "0.40       0.40         0.318036      1.000000  0.482591  0.988828\n",
      "0.50       0.50         0.367157      1.000000  0.537110  0.991020\n",
      "0.60       0.60         0.418746      0.999072  0.590143  0.992770\n",
      "0.70       0.70         0.478022      0.997371  0.646290  0.994312\n",
      "0.80       0.80         0.549516      0.991185  0.707044  0.995721\n",
      "0.90       0.90         0.658277      0.966749  0.783235  0.997212\n",
      "Best Threshold: 0.9000\n",
      "Best Accuracy: 0.9972\n",
      "Best Precision: 0.6583\n",
      "Best Recall: 0.9667\n",
      "Best F1 Score: 0.7832\n",
      "Best ROC_AUC Score: 0.9821\n"
     ]
    }
   ],
   "source": [
    "for i in numbers:\n",
    "    cm1 = confusion_matrix(y_train_results['y_train_actual'], y_train_results[i])\n",
    "    TP, FP, FN, TN = cm1[1,1], cm1[0,1], cm1[1,0], cm1[0,0]\n",
    "    \n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    f1_score_value = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    \n",
    "    cutoff_df.loc[i] = [i, precision, recall, f1_score_value, accuracy]\n",
    "\n",
    "print(cutoff_df)\n",
    "\n",
    "best_idx = cutoff_df['F1_score'].idxmax()\n",
    "best_threshold = cutoff_df.loc[best_idx, 'Threshold']\n",
    "best_f1_score = cutoff_df.loc[best_idx, 'F1_score']\n",
    "best_precision = cutoff_df.loc[best_idx, 'precision_score']\n",
    "best_recall = cutoff_df.loc[best_idx, 'recall_score']\n",
    "best_accuracy = cutoff_df.loc[best_idx, 'Accuracy']\n",
    "best_auc = roc_auc_score(y_train_results['y_train_actual'], y_train_results[best_threshold])\n",
    "\n",
    "print(f'Best Threshold: {best_threshold:.4f}')\n",
    "print(f'Best Accuracy: {best_accuracy:.4f}')\n",
    "print(f'Best Precision: {best_precision:.4f}')\n",
    "print(f'Best Recall: {best_recall:.4f}')\n",
    "print(f'Best F1 Score: {best_f1_score:.4f}')\n",
    "print(f'Best ROC_AUC Score: {best_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Threshold  precision_score  recall_score  F1_score  Accuracy\n",
      "0.10       0.10         0.156484      0.984301  0.270037  0.972273\n",
      "0.15       0.15         0.185068      0.976766  0.311178  0.977469\n",
      "0.20       0.20         0.211867      0.974254  0.348046  0.980983\n",
      "0.30       0.30         0.258225      0.963579  0.407299  0.985388\n",
      "0.40       0.40         0.302316      0.958870  0.459697  0.988256\n",
      "0.50       0.50         0.346057      0.953532  0.507817  0.990370\n",
      "0.60       0.60         0.391197      0.945997  0.553504  0.992048\n",
      "0.70       0.70         0.447748      0.936264  0.605790  0.993651\n",
      "0.80       0.80         0.513528      0.917739  0.658556  0.995042\n",
      "0.90       0.90         0.620223      0.891680  0.731582  0.996591\n",
      "Best Threshold: 0.9000\n",
      "Best Accuracy: 0.9966\n",
      "Best Precision: 0.6202\n",
      "Best Recall: 0.8917\n",
      "Best F1 Score: 0.7316\n",
      "Best ROC_AUC Score: 0.9444\n"
     ]
    }
   ],
   "source": [
    "for i in numbers:\n",
    "    cm1 = confusion_matrix(y_test_results['y_test_actual'], y_test_results[i])\n",
    "    TP, FP, FN, TN = cm1[1,1], cm1[0,1], cm1[1,0], cm1[0,0]\n",
    "    \n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    f1_score_value = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    \n",
    "    cutoff_df.loc[i] = [i, precision, recall, f1_score_value, accuracy]\n",
    "\n",
    "print(cutoff_df)\n",
    "\n",
    "best_idx = cutoff_df['F1_score'].idxmax()\n",
    "best_threshold = cutoff_df.loc[best_idx, 'Threshold']\n",
    "best_f1_score = cutoff_df.loc[best_idx, 'F1_score']\n",
    "best_precision = cutoff_df.loc[best_idx, 'precision_score']\n",
    "best_recall = cutoff_df.loc[best_idx, 'recall_score']\n",
    "best_accuracy = cutoff_df.loc[best_idx, 'Accuracy']\n",
    "best_auc = roc_auc_score(y_test_results['y_test_actual'], y_test_results[best_threshold])\n",
    "\n",
    "print(f'Best Threshold: {best_threshold:.4f}')\n",
    "print(f'Best Accuracy: {best_accuracy:.4f}')\n",
    "print(f'Best Precision: {best_precision:.4f}')\n",
    "print(f'Best Recall: {best_recall:.4f}')\n",
    "print(f'Best F1 Score: {best_f1_score:.4f}')\n",
    "print(f'Best ROC_AUC Score: {best_auc:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
