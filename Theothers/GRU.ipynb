{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(r'/home/ducanh/Credit Card Transactions Fraud Detection/Datasets/fraudTrain.csv')\n",
    "df_test = pd.read_csv(r'/home/ducanh/Credit Card Transactions Fraud Detection/Datasets/fraudTest.csv')\n",
    "df = pd.concat([df_train, df_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset:\n",
      "Tổng số giao dịch: 1296675\n",
      "Số lượng cc_num khác nhau: 983\n",
      "\n",
      "Test dataset:\n",
      "Tổng số giao dịch: 555719\n",
      "Số lượng cc_num khác nhau: 924\n"
     ]
    }
   ],
   "source": [
    "# Số lượng giao dịch và số lượng cc_num khác nhau cho tập train\n",
    "print(\"Train dataset:\")\n",
    "print(\"Tổng số giao dịch:\", df_train.shape[0])\n",
    "print(\"Số lượng cc_num khác nhau:\", df_train['cc_num'].nunique())\n",
    "print()\n",
    "\n",
    "# Số lượng giao dịch và số lượng cc_num khác nhau cho tập test\n",
    "print(\"Test dataset:\")\n",
    "print(\"Tổng số giao dịch:\", df_test.shape[0])\n",
    "print(\"Số lượng cc_num khác nhau:\", df_test['cc_num'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng features trong tập train: 22\n",
      "Số lượng features trong tập test: 22\n",
      "\n",
      "Tỷ lệ fraud/non-fraud trong tập train:\n",
      "is_fraud\n",
      "0    99.421135\n",
      "1     0.578865\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Tỷ lệ fraud/non-fraud trong tập test:\n",
      "is_fraud\n",
      "0    99.614014\n",
      "1     0.385986\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Tỷ lệ fraud/non-fraud sau khi gộp:\n",
      "is_fraud\n",
      "0    99.478999\n",
      "1     0.521001\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# In số lượng features\n",
    "num_features_train = df_train.shape[1] - 1  # Trừ cột nhãn\n",
    "num_features_test = df_test.shape[1] - 1\n",
    "\n",
    "print(\"Số lượng features trong tập train:\", num_features_train)\n",
    "print(\"Số lượng features trong tập test:\", num_features_test)\n",
    "\n",
    "# Tính tỷ lệ fraud/non-fraud trong tập train\n",
    "fraud_ratio_train = df_train['is_fraud'].value_counts(normalize=True) * 100\n",
    "print(\"\\nTỷ lệ fraud/non-fraud trong tập train:\")\n",
    "print(fraud_ratio_train)\n",
    "\n",
    "# Tính tỷ lệ fraud/non-fraud trong tập test\n",
    "fraud_ratio_test = df_test['is_fraud'].value_counts(normalize=True) * 100\n",
    "print(\"\\nTỷ lệ fraud/non-fraud trong tập test:\")\n",
    "print(fraud_ratio_test)\n",
    "\n",
    "# Tính tỷ lệ fraud/non-fraud sau khi gộp\n",
    "fraud_ratio_total = df['is_fraud'].value_counts(normalize=True) * 100\n",
    "print(\"\\nTỷ lệ fraud/non-fraud sau khi gộp:\")\n",
    "print(fraud_ratio_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tổng số giao dịch: 1852394\n",
      "Danh sách cc_num:\n",
      "0         2703186189652095\n",
      "1             630423337322\n",
      "2           38859492057661\n",
      "3         3534093764340240\n",
      "4          375534208663984\n",
      "                ...       \n",
      "555714      30560609640617\n",
      "555715    3556613125071656\n",
      "555716    6011724471098086\n",
      "555717       4079773899158\n",
      "555718    4170689372027579\n",
      "Name: cc_num, Length: 1852394, dtype: int64\n",
      "Số lượng cc_num khác nhau: 999\n"
     ]
    }
   ],
   "source": [
    "# In ra số lượng giao dịch\n",
    "print(\"Tổng số giao dịch:\", df.shape[0])\n",
    "\n",
    "# In ra cột cc_num\n",
    "print(\"Danh sách cc_num:\")\n",
    "print(df['cc_num'])\n",
    "print(\"Số lượng cc_num khác nhau:\", df['cc_num'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3135149/4057584870.py:21: FutureWarning: The provided callable <function mean at 0x716184269f30> is currently using DataFrameGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n",
      "  age_piv_2 = pd.pivot_table(data=df,\n",
      "/tmp/ipykernel_3135149/4057584870.py:36: FutureWarning: The provided callable <function mean at 0x716184269f30> is currently using DataFrameGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n",
      "  job_txn_piv_2 = pd.pivot_table(data=df,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (1241103, 11)\n",
      "Test shape: (611291, 11)\n",
      "Shape of training data: ((1241103, 9), (1241103,))\n",
      "Shape of testing data: ((611291, 9), (611291,))\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(r'/home/ducanh/Credit Card Transactions Fraud Detection/Datasets/fraudTrain.csv')\n",
    "df_test = pd.read_csv(r'/home/ducanh/Credit Card Transactions Fraud Detection/Datasets/fraudTest.csv')\n",
    "df = pd.concat([df_train, df_test])\n",
    "\n",
    "# Xử lý thời gian\n",
    "df['trans_date_trans_time'] = pd.to_datetime(df['trans_date_trans_time'])\n",
    "df['trans_hour'] = df['trans_date_trans_time'].dt.time.apply(lambda x: str(x)[:2])\n",
    "\n",
    "df['dob'] = pd.to_datetime(df['dob'])\n",
    "df['cust_age'] = df['dob'].dt.year.apply(lambda x: 2021 - x)\n",
    "df['cust_age_groups'] = df['cust_age'].apply(lambda x: 'below 10' if x < 10 else ('10-20' if x >= 10 and x < 20 else ('20-30' if x >= 20 and x < 30 else ('30-40' if x >= 30 and x < 40 else ('40-50' if x >= 40 and x < 50 else ('50-60' if x >= 50 and x < 60 else ('60-70' if x >= 60 and x < 70 else ('70-80' if x >= 70 and x < 80 else 'Above 80'))))))))\n",
    "\n",
    "# =============================================================================\n",
    "# Drop các cột không cần thiết, tuy nhiên không drop 'trans_date_trans_time' và 'cc_num'\n",
    "# =============================================================================\n",
    "drop_col = ['Unnamed: 0', 'merchant', 'first', 'last', 'street', 'city', 'state', 'lat',\n",
    "            'long','dob', 'unix_time', 'cust_age', 'merch_lat', 'merch_long', 'city_pop']\n",
    "df.drop(drop_col, axis=1, inplace=True)\n",
    "\n",
    "# Pivot table cho cust_age_groups\n",
    "age_piv_2 = pd.pivot_table(data=df,\n",
    "                           index='cust_age_groups',\n",
    "                           columns='is_fraud',\n",
    "                           values='amt',\n",
    "                           aggfunc=np.mean)\n",
    "age_piv_2.sort_values(by=1, ascending=True, inplace=True)\n",
    "age_dic = {k: v for (k, v) in zip(age_piv_2.index.values, age_piv_2.reset_index().index.values)}\n",
    "df['cust_age_groups'] = df['cust_age_groups'].map(age_dic)\n",
    "\n",
    "# Pivot table cho category\n",
    "merch_cat = df[df['is_fraud'] == 1].groupby('category')['amt'].mean().sort_values(ascending=True)\n",
    "merch_cat_dic = {k: v for (k, v) in zip(merch_cat.index.values, merch_cat.reset_index().index.values)}\n",
    "df['category'] = df['category'].map(merch_cat_dic)\n",
    "\n",
    "# Pivot table cho job\n",
    "job_txn_piv_2 = pd.pivot_table(data=df,\n",
    "                               index='job',\n",
    "                               columns='is_fraud',\n",
    "                               values='amt',\n",
    "                               aggfunc=np.mean)\n",
    "job_cat_dic = {k: v for (k, v) in zip(job_txn_piv_2.index.values, job_txn_piv_2.reset_index().index.values)}\n",
    "df['job'] = df['job'].map(job_cat_dic)\n",
    "\n",
    "df['trans_hour'] = df['trans_hour'].astype('int')\n",
    "df = pd.get_dummies(data=df, columns=['gender'], drop_first=True, dtype='int')\n",
    "\n",
    "# =============================================================================\n",
    "# Chuyển đổi trans_date_trans_time thành timestamp (dạng số) để có thể scale\n",
    "# =============================================================================\n",
    "df['trans_date_trans_time'] = df['trans_date_trans_time'].apply(lambda x: x.timestamp())\n",
    "\n",
    "# =============================================================================\n",
    "# 2️⃣ Train_test_split\n",
    "# =============================================================================\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.33, random_state=42, stratify=df['is_fraud'])\n",
    "print(\"Train shape:\", train.shape)\n",
    "print(\"Test shape:\", test.shape)\n",
    "\n",
    "# Drop cột trans_num từ cả train và test\n",
    "train.drop('trans_num', axis=1, inplace=True)\n",
    "test.drop('trans_num', axis=1, inplace=True)\n",
    "\n",
    "# Tách features và label\n",
    "y_train = train['is_fraud']\n",
    "X_train = train.drop('is_fraud', axis=1)\n",
    "\n",
    "y_test = test['is_fraud']\n",
    "X_test = test.drop('is_fraud', axis=1)\n",
    "\n",
    "print('Shape of training data:', (X_train.shape, y_train.shape))\n",
    "print('Shape of testing data:', (X_test.shape, y_test.shape))\n",
    "\n",
    "# =============================================================================\n",
    "# 3️⃣ Scaling dữ liệu\n",
    "# =============================================================================\n",
    "sc = StandardScaler()\n",
    "X_train_sc = sc.fit_transform(X_train)\n",
    "X_test_sc = sc.transform(X_test)\n",
    "\n",
    "# Convert lại thành DataFrame\n",
    "X_train_sc = pd.DataFrame(data=X_train_sc, columns=X_train.columns)\n",
    "X_test_sc = pd.DataFrame(data=X_test_sc, columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence shape (train): (1231518, 10, 8)\n",
      "Sequence shape (test): (601995, 10, 8)\n"
     ]
    }
   ],
   "source": [
    "sequence_length = 10  # Số giao dịch cần trong 1 sequence\n",
    "\n",
    "def create_sequences_predict_all(df, sequence_length):\n",
    "    sequences, labels = [], []\n",
    "    # Nhóm theo cc_num\n",
    "    grouped = df.groupby('cc_num')\n",
    "    for user_id, group in grouped:\n",
    "        # Sắp xếp theo trans_date_trans_time (đã chuyển thành timestamp)\n",
    "        group = group.sort_values(by='trans_date_trans_time')\n",
    "        # Lấy các giá trị: loại bỏ 'is_fraud' và 'cc_num'\n",
    "        values = group.drop(columns=['is_fraud', 'cc_num']).values\n",
    "        targets = group['is_fraud'].values\n",
    "        n = len(group)\n",
    "        for i in range(n):\n",
    "            if i < sequence_length:\n",
    "                # Nếu số giao dịch hiện có nhỏ hơn sequence_length\n",
    "                pad_needed = sequence_length - (i + 1)\n",
    "                # Replicate giao dịch đầu tiên cho đủ số lượng pad\n",
    "                pad = np.repeat(values[0:1, :], pad_needed, axis=0)\n",
    "                seq = np.concatenate((pad, values[:i+1]), axis=0)\n",
    "            else:\n",
    "                # Nếu đủ giao dịch, lấy sequence gồm các giao dịch từ (i-sequence_length+1) đến i\n",
    "                seq = values[i-sequence_length+1:i+1]\n",
    "            sequences.append(seq)\n",
    "            labels.append(targets[i])\n",
    "    return np.array(sequences), np.array(labels)\n",
    "\n",
    "# Gộp thêm cột 'is_fraud' vào DataFrame scale để tạo sequence\n",
    "train_seq_df = X_train_sc.copy()\n",
    "train_seq_df['is_fraud'] = y_train.values\n",
    "\n",
    "test_seq_df = X_test_sc.copy()\n",
    "test_seq_df['is_fraud'] = y_test.values\n",
    "\n",
    "X_train_seq, y_train_seq = create_sequences_predict_all(train_seq_df, sequence_length)\n",
    "X_test_seq, y_test_seq = create_sequences_predict_all(test_seq_df, sequence_length)\n",
    "\n",
    "print(\"Sequence shape (train):\", X_train_seq.shape)\n",
    "print(\"Sequence shape (test):\", X_test_seq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FraudDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X  # shape: (num_sequences, sequence_length, num_features)\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "batch_size = 64\n",
    "train_dataset = FraudDataset(torch.tensor(X_train_seq, dtype=torch.float32),\n",
    "                               torch.tensor(y_train_seq, dtype=torch.float32))\n",
    "test_dataset = FraudDataset(torch.tensor(X_test_seq, dtype=torch.float32),\n",
    "                              torch.tensor(y_test_seq, dtype=torch.float32))\n",
    "\n",
    "# Shuffle chỉ xáo trộn thứ tự các sequence, không làm xáo trộn bên trong mỗi sequence\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# =============================================================================\n",
    "# 6. Xây dựng mô hình GRU\n",
    "# =============================================================================\n",
    "class FraudGRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(FraudGRU, self).__init__()\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out, _ = self.gru(x)\n",
    "        # Lấy trạng thái ẩn của bước thời gian cuối cùng\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return self.sigmoid(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.0144\n",
      "Epoch 2, Loss: 0.0107\n",
      "Epoch 3, Loss: 0.0097\n",
      "Epoch 4, Loss: 0.0092\n",
      "Epoch 5, Loss: 0.0088\n",
      "Epoch 6, Loss: 0.0086\n",
      "Epoch 7, Loss: 0.0083\n",
      "Epoch 8, Loss: 0.0081\n",
      "Epoch 9, Loss: 0.0079\n",
      "Epoch 10, Loss: 0.0077\n",
      "Epoch 11, Loss: 0.0076\n",
      "Epoch 12, Loss: 0.0075\n",
      "Epoch 13, Loss: 0.0073\n",
      "Epoch 14, Loss: 0.0071\n",
      "Epoch 15, Loss: 0.0069\n",
      "Epoch 16, Loss: 0.0070\n",
      "Epoch 17, Loss: 0.0068\n",
      "Epoch 18, Loss: 0.0067\n",
      "Epoch 19, Loss: 0.0066\n",
      "Epoch 20, Loss: 0.0067\n",
      "Epoch 21, Loss: 0.0067\n",
      "Epoch 22, Loss: 0.0066\n",
      "Epoch 23, Loss: 0.0066\n",
      "Epoch 24, Loss: 0.0066\n",
      "Epoch 25, Loss: 0.0065\n",
      "Epoch 26, Loss: 0.0067\n",
      "Epoch 27, Loss: 0.0066\n",
      "Epoch 28, Loss: 0.0066\n",
      "Epoch 29, Loss: 0.0066\n",
      "Epoch 30, Loss: 0.0067\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, train_loader, criterion, optimizer, num_epochs, device):\n",
    "    best_loss = float('inf')\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch).squeeze()\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        average_loss = total_loss / len(train_loader)\n",
    "        print(f'Epoch {epoch + 1}, Loss: {average_loss:.4f}')\n",
    "        \n",
    "        # Lưu checkpoint cuối cùng của epoch (last.pth)\n",
    "        torch.save(model.state_dict(), 'last.pth')\n",
    "        \n",
    "        # Nếu loss giảm, lưu checkpoint mô hình tốt nhất (best.pth)\n",
    "        if average_loss < best_loss:\n",
    "            best_loss = average_loss\n",
    "            torch.save(model.state_dict(), 'best.pth')\n",
    "\n",
    "input_size = X_train_seq.shape[2]  # số feature (sau khi loại bỏ cc_num)\n",
    "hidden_size = 64\n",
    "num_layers = 2\n",
    "model = FraudGRU(input_size, hidden_size, num_layers)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "num_epochs = 30\n",
    "train_model(model, train_loader, criterion, optimizer, num_epochs, device)\n",
    "\n",
    "# =============================================================================\n",
    "# 8️⃣ Dự đoán và đánh giá mô hình\n",
    "# =============================================================================\n",
    "model.eval()\n",
    "y_pred_train_proba = []\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        outputs = model(X_batch).squeeze().cpu().numpy()\n",
    "        y_pred_train_proba.extend(outputs)\n",
    "y_pred_train_proba = np.array(y_pred_train_proba)\n",
    "\n",
    "# --- 2. Lấy predicted probabilities cho tập test ---\n",
    "y_pred_test_proba = []\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        outputs = model(X_batch).squeeze().cpu().numpy()\n",
    "        y_pred_test_proba.extend(outputs)\n",
    "y_pred_test_proba = np.array(y_pred_test_proba)\n",
    "\n",
    "# --- 3. Tạo DataFrame kết quả cho train và test ---\n",
    "# Lưu ý: ở đây chúng ta dùng y_train_seq và y_test_seq (là nhãn của sequence)\n",
    "y_train_results = pd.DataFrame(y_pred_train_proba, columns=['pred_fraud'])\n",
    "y_train_results['pred_not_fraud'] = 1 - y_train_results['pred_fraud']\n",
    "y_train_results['y_train_actual'] = y_train_seq  # y_train_seq là nhãn thực của các sequence\n",
    "\n",
    "y_test_results = pd.DataFrame(y_pred_test_proba, columns=['pred_fraud'])\n",
    "y_test_results['pred_not_fraud'] = 1 - y_test_results['pred_fraud']\n",
    "y_test_results['y_test_actual'] = y_test_seq\n",
    "\n",
    "# --- 4. Đánh giá với các ngưỡng khác nhau ---\n",
    "numbers = [0.1, 0.15, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "for i in numbers:\n",
    "    y_train_results[i] = y_train_results['pred_fraud'].map(lambda x: 1 if x > i else 0)\n",
    "    y_test_results[i] = y_test_results['pred_fraud'].map(lambda x: 1 if x > i else 0)\n",
    "\n",
    "cutoff_df = pd.DataFrame(columns=['Threshold', 'precision_score', 'recall_score', 'F1_score', 'Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Evaluation:\n",
      "      Threshold  precision_score  recall_score  F1_score  Accuracy\n",
      "0.10       0.10         0.005013      0.005080  0.005046  0.990394\n",
      "0.15       0.15         0.005261      0.005080  0.005169  0.990624\n",
      "0.20       0.20         0.005429      0.005080  0.005249  0.990767\n",
      "0.30       0.30         0.005520      0.004911  0.005198  0.990986\n",
      "0.40       0.40         0.005402      0.004572  0.004953  0.991191\n",
      "0.50       0.50         0.005232      0.004234  0.004680  0.991366\n",
      "0.60       0.60         0.005509      0.004234  0.004788  0.991561\n",
      "0.70       0.70         0.005397      0.003895  0.004524  0.991782\n",
      "0.80       0.80         0.005120      0.003387  0.004077  0.992066\n",
      "0.90       0.90         0.004227      0.002371  0.003038  0.992538\n",
      "Best Threshold (Train): 0.2000\n",
      "Best Accuracy (Train): 0.9908\n",
      "Best Precision (Train): 0.0054\n",
      "Best Recall (Train): 0.0051\n",
      "Best F1 Score (Train): 0.0052\n",
      "Best ROC_AUC Score (Train): 0.4966\n"
     ]
    }
   ],
   "source": [
    "for i in numbers:\n",
    "    cm1 = confusion_matrix(y_train_results['y_train_actual'], y_train_results[i])\n",
    "    TP, FP, FN, TN = cm1[1,1], cm1[0,1], cm1[1,0], cm1[0,0]\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    f1_score_value = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    cutoff_df.loc[i] = [i, precision, recall, f1_score_value, accuracy]\n",
    "\n",
    "print(\"Train Evaluation:\")\n",
    "print(cutoff_df)\n",
    "\n",
    "best_idx = cutoff_df['F1_score'].idxmax()\n",
    "best_threshold = cutoff_df.loc[best_idx, 'Threshold']\n",
    "best_precision = cutoff_df.loc[best_idx, 'precision_score']\n",
    "best_recall = cutoff_df.loc[best_idx, 'recall_score']\n",
    "best_f1_score = cutoff_df.loc[best_idx, 'F1_score']\n",
    "best_accuracy = cutoff_df.loc[best_idx, 'Accuracy']\n",
    "best_auc = roc_auc_score(y_train_results['y_train_actual'], y_train_results['pred_fraud'])\n",
    "\n",
    "print(f'Best Threshold (Train): {best_threshold:.4f}')\n",
    "print(f'Best Accuracy (Train): {best_accuracy:.4f}')\n",
    "print(f'Best Precision (Train): {best_precision:.4f}')\n",
    "print(f'Best Recall (Train): {best_recall:.4f}')\n",
    "print(f'Best F1 Score (Train): {best_f1_score:.4f}')\n",
    "print(f'Best ROC_AUC Score (Train): {best_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Evaluation:\n",
      "      Threshold  precision_score  recall_score  F1_score  Accuracy\n",
      "0.10       0.10         0.543315      0.552741  0.547988  0.995635\n",
      "0.15       0.15         0.570853      0.540944  0.555496  0.995855\n",
      "0.20       0.20         0.586154      0.528799  0.556001  0.995957\n",
      "0.30       0.30         0.605482      0.505899  0.551229  0.996056\n",
      "0.40       0.40         0.622717      0.485080  0.545348  0.996128\n",
      "0.50       0.50         0.635244      0.465302  0.537152  0.996161\n",
      "0.60       0.60         0.649897      0.439278  0.524224  0.996183\n",
      "0.70       0.70         0.658699      0.411173  0.506302  0.996161\n",
      "0.80       0.80         0.674843      0.372311  0.479875  0.996136\n",
      "0.90       0.90         0.686441      0.309160  0.426316  0.996017\n",
      "Best Threshold (Test): 0.2000\n",
      "Best Accuracy (Test): 0.9960\n",
      "Best Precision (Test): 0.5862\n",
      "Best Recall (Test): 0.5288\n",
      "Best F1 Score (Test): 0.5560\n",
      "Best ROC_AUC Score (Test): 0.8346\n"
     ]
    }
   ],
   "source": [
    "cutoff_df_test = pd.DataFrame(columns=['Threshold', 'precision_score', 'recall_score', 'F1_score', 'Accuracy'])\n",
    "for i in numbers:\n",
    "    cm1 = confusion_matrix(y_test_results['y_test_actual'], y_test_results[i])\n",
    "    TP, FP, FN, TN = cm1[1,1], cm1[0,1], cm1[1,0], cm1[0,0]\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    f1_score_value = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    cutoff_df_test.loc[i] = [i, precision, recall, f1_score_value, accuracy]\n",
    "\n",
    "print(\"Test Evaluation:\")\n",
    "print(cutoff_df_test)\n",
    "\n",
    "best_idx_test = cutoff_df_test['F1_score'].idxmax()\n",
    "best_threshold_test = cutoff_df_test.loc[best_idx_test, 'Threshold']\n",
    "best_precision_test = cutoff_df_test.loc[best_idx_test, 'precision_score']\n",
    "best_recall_test = cutoff_df_test.loc[best_idx_test, 'recall_score']\n",
    "best_f1_score_test = cutoff_df_test.loc[best_idx_test, 'F1_score']\n",
    "best_accuracy_test = cutoff_df_test.loc[best_idx_test, 'Accuracy']\n",
    "best_auc_test = roc_auc_score(y_test_results['y_test_actual'], y_test_results['pred_fraud'])\n",
    "\n",
    "print(f'Best Threshold (Test): {best_threshold_test:.4f}')\n",
    "print(f'Best Accuracy (Test): {best_accuracy_test:.4f}')\n",
    "print(f'Best Precision (Test): {best_precision_test:.4f}')\n",
    "print(f'Best Recall (Test): {best_recall_test:.4f}')\n",
    "print(f'Best F1 Score (Test): {best_f1_score_test:.4f}')\n",
    "print(f'Best ROC_AUC Score (Test): {best_auc_test:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
